<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>Opus 4.5 vs Opus 4.6: An Exploratory Case Study</title>
        <link href="https://fonts.googleapis.com/css2?family=Poppins:wght@400;500;600;700&family=Lora:ital,wght@0,400;0,500;0,600;1,400&display=swap" rel="stylesheet">
        <style>
        :root {
            --dark: #141413;
            --light: #faf9f5;
            --mid-gray: #b0aea5;
            --light-gray: #e8e6dc;
            --orange: #d97757;
            --blue: #6a9bcc;
            --green: #788c5d;
            --orange-light: #d9775720;
            --blue-light: #6a9bcc20;
            --green-light: #788c5d20;
            --red-soft: #c4705a;
        }

        * { margin: 0; padding: 0; box-sizing: border-box; }

        body {
            font-family: 'Lora', Georgia, serif;
            background: var(--light);
            color: var(--dark);
            line-height: 1.6;
            font-size: 15px;
        }

        .page {
            max-width: 880px;
            margin: 0 auto;
            padding: 3rem 2rem 4rem;
        }

        /* -- Header -- */
        header {
            border-bottom: 2px solid var(--dark);
            padding-bottom: 1.5rem;
            margin-bottom: 2.5rem;
        }
        header .eyebrow {
            font-family: 'Poppins', Arial, sans-serif;
            font-size: 0.7rem;
            font-weight: 600;
            letter-spacing: 0.12em;
            text-transform: uppercase;
            color: var(--orange);
            margin-bottom: 0.3rem;
        }
        header h1 {
            font-family: 'Poppins', Arial, sans-serif;
            font-size: 2rem;
            font-weight: 700;
            line-height: 1.15;
            color: var(--dark);
        }
        header .subtitle {
            font-family: 'Lora', Georgia, serif;
            font-style: italic;
            color: var(--mid-gray);
            margin-top: 0.4rem;
            font-size: 1.05rem;
        }
        header .meta {
            font-family: 'Poppins', Arial, sans-serif;
            font-size: 0.72rem;
            color: var(--mid-gray);
            margin-top: 0.8rem;
            letter-spacing: 0.03em;
        }

        /* -- Sections -- */
        section { margin-bottom: 2.5rem; padding-top: 1.5rem; }

        h2 {
            font-family: 'Poppins', Arial, sans-serif;
            font-size: 1.35rem;
            font-weight: 600;
            color: var(--dark);
            border-bottom: 1px solid var(--light-gray);
            padding-bottom: 0.35rem;
            margin-bottom: 1rem;
        }

        h3 {
            font-family: 'Poppins', Arial, sans-serif;
            font-size: 0.9rem;
            font-weight: 600;
            color: var(--dark);
            margin: 1.4rem 0 0.6rem;
        }

        p {
            margin-bottom: 0.8rem;
            text-align: justify;
        }

        /* -- Stat Cards -- */
        .stat-row {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(160px, 1fr));
            gap: 0.8rem;
            margin-bottom: 1.5rem;
        }
        .stat-card {
            background: white;
            border: 1px solid var(--light-gray);
            border-radius: 6px;
            padding: 0.9rem 1rem;
        }
        .stat-card .label {
            font-family: 'Poppins', Arial, sans-serif;
            font-size: 0.65rem;
            font-weight: 600;
            text-transform: uppercase;
            letter-spacing: 0.08em;
            color: var(--mid-gray);
            margin-bottom: 0.15rem;
        }
        .stat-card .value {
            font-family: 'Poppins', Arial, sans-serif;
            font-size: 1.35rem;
            font-weight: 700;
        }
        .stat-card .detail {
            font-size: 0.78rem;
            color: var(--mid-gray);
        }
        .v-orange { color: var(--orange); }
        .v-blue   { color: var(--blue); }
        .v-green  { color: var(--green); }
        .v-dark   { color: var(--dark); }

        /* -- Tables -- */
        table {
            width: 100%;
            border-collapse: collapse;
            margin-bottom: 1.2rem;
            font-size: 0.85rem;
        }
        thead th {
            font-family: 'Poppins', Arial, sans-serif;
            font-size: 0.68rem;
            font-weight: 600;
            text-transform: uppercase;
            letter-spacing: 0.06em;
            color: var(--mid-gray);
            text-align: left;
            padding: 0.45rem 0.6rem;
            border-bottom: 1.5px solid var(--dark);
            white-space: nowrap;
        }
        thead th.right { text-align: right; }
        tbody td {
            padding: 0.4rem 0.6rem;
            border-bottom: 1px solid var(--light-gray);
            vertical-align: middle;
        }
        tbody tr:last-child td { border-bottom: 1.5px solid var(--dark); }
        td.right { text-align: right; font-variant-numeric: tabular-nums; }
        td.label-cell {
            font-family: 'Poppins', Arial, sans-serif;
            font-size: 0.8rem;
            font-weight: 500;
        }
        td.mono {
            font-family: 'Poppins', Arial, sans-serif;
            font-variant-numeric: tabular-nums;
            font-size: 0.82rem;
        }

        /* -- Inline Bars -- */
        .bar-cell {
            padding: 0.3rem 0.6rem;
            min-width: 180px;
        }
        .bar-pair {
            display: flex;
            flex-direction: column;
            gap: 2px;
        }
        .bar-row {
            display: flex;
            align-items: center;
            gap: 6px;
            height: 16px;
        }
        .bar-tag {
            font-family: 'Poppins', Arial, sans-serif;
            font-size: 0.6rem;
            font-weight: 600;
            width: 14px;
            flex-shrink: 0;
            text-align: right;
            color: var(--mid-gray);
        }
        .bar-track {
            flex: 1;
            height: 10px;
            background: var(--light-gray);
            border-radius: 2px;
            overflow: hidden;
            position: relative;
        }
        .bar-ci {
            position: absolute;
            top: 1px;
            height: 8px;
            border-left: 1.5px solid rgba(0,0,0,0.4);
            border-right: 1.5px solid rgba(0,0,0,0.4);
        }
        .bar-ci::after {
            content: '';
            position: absolute;
            top: 50%;
            left: 0;
            right: 0;
            height: 1.5px;
            background: rgba(0,0,0,0.3);
            transform: translateY(-50%);
        }
        .bar-fill {
            height: 100%;
            border-radius: 2px;
            transition: width 0.4s ease;
        }
        .bar-fill.a { background: var(--orange); }
        .bar-fill.b { background: var(--blue); }
        .bar-fill.green { background: var(--green); }
        .bar-fill.red { background: var(--red-soft); }
        .bar-val {
            font-family: 'Poppins', Arial, sans-serif;
            font-size: 0.68rem;
            font-weight: 500;
            min-width: 34px;
            text-align: right;
            font-variant-numeric: tabular-nums;
        }

        /* single bar variant */
        .bar-single {
            display: flex;
            align-items: center;
            gap: 6px;
            height: 16px;
        }

        /* -- Callout -- */
        .callout {
            background: white;
            border-left: 3px solid var(--orange);
            padding: 0.8rem 1rem;
            margin: 1rem 0 1.2rem;
            font-size: 0.88rem;
            text-align: justify;
        }
        .callout strong {
            font-family: 'Poppins', Arial, sans-serif;
            font-size: 0.78rem;
        }
        .callout.blue { border-left-color: var(--blue); }
        .callout.green { border-left-color: var(--green); }

        /* -- Legend -- */
        .legend {
            display: flex;
            gap: 1.2rem;
            margin-bottom: 0.8rem;
            font-family: 'Poppins', Arial, sans-serif;
            font-size: 0.72rem;
            font-weight: 500;
            color: var(--mid-gray);
        }
        .legend span {
            display: flex;
            align-items: center;
            gap: 4px;
        }
        .legend .dot {
            width: 10px;
            height: 10px;
            border-radius: 2px;
            display: inline-block;
        }
        .dot-a { background: var(--orange); }
        .dot-b { background: var(--blue); }

        /* -- Pipeline -- */
        .pipeline {
            display: flex;
            align-items: center;
            gap: 0.3rem 0;
            margin: 1rem 0 1.5rem;
            flex-wrap: wrap;
            justify-content: center;
        }
        .pipe-step {
            background: white;
            border: 1px solid var(--light-gray);
            border-radius: 5px;
            padding: 0.45rem 0.6rem;
            font-family: 'Poppins', Arial, sans-serif;
            font-size: 0.68rem;
            font-weight: 500;
            text-align: center;
            min-width: 80px;
        }
        .pipe-step small {
            display: block;
            font-size: 0.58rem;
            color: var(--mid-gray);
            font-weight: 400;
        }
        .pipe-arrow {
            font-size: 0.8rem;
            color: var(--mid-gray);
            padding: 0 0.15rem;
        }

        /* -- Side-by-side profile cards -- */
        .profile-grid {
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 1rem;
            margin-bottom: 1.5rem;
        }
        .profile-card {
            background: white;
            border: 1px solid var(--light-gray);
            border-radius: 6px;
            padding: 0.9rem 1rem;
        }
        .profile-card p {
            font-size: 0.82rem;
            margin: 0.4rem 0 0;
        }

        /* -- Footer -- */
        footer {
            border-top: 1px solid var(--light-gray);
            padding-top: 1rem;
            margin-top: 2rem;
            font-family: 'Poppins', Arial, sans-serif;
            font-size: 0.7rem;
            color: var(--mid-gray);
        }

        /* responsive */
        @media (max-width: 640px) {
            .page { padding: 1.5rem 1rem; }
            header h1 { font-size: 1.5rem; }
            .stat-row { grid-template-columns: 1fr 1fr; }
            .bar-cell { min-width: 120px; }
            .profile-grid { grid-template-columns: 1fr; }
        }

        /* -- Table of Contents -- */
        .toc {
            background: white;
            border: 1px solid var(--light-gray);
            border-radius: 6px;
            padding: 1.2rem 1.5rem;
            margin: 1.5rem 0 2.5rem;
        }
        .toc-title {
            font-family: 'Poppins', Arial, sans-serif;
            font-size: 0.72rem;
            font-weight: 600;
            text-transform: uppercase;
            letter-spacing: 0.08em;
            color: var(--mid-gray);
            margin-bottom: 0.8rem;
        }
        .toc ol {
            list-style: none;
            padding: 0;
            margin: 0;
            counter-reset: toc 0;
        }
        .toc li {
            counter-increment: toc;
            padding: 0.35rem 0;
            border-bottom: 1px solid var(--light-gray);
        }
        .toc li:last-child { border-bottom: none; }
        .toc li::before {
            content: counter(toc) ". ";
            font-family: 'Poppins', Arial, sans-serif;
            font-weight: 600;
            font-size: 0.78rem;
            color: var(--mid-gray);
        }
        .toc a {
            font-family: 'Poppins', Arial, sans-serif;
            font-size: 0.82rem;
            font-weight: 500;
            color: var(--dark);
            text-decoration: none;
        }
        .toc a:hover { color: var(--blue); }
        .toc .finding {
            font-family: 'Lora', Georgia, serif;
            font-size: 0.78rem;
            font-style: italic;
            color: var(--mid-gray);
            display: block;
            padding-left: 1.6rem;
            margin-top: 0.15rem;
        }

        /* -- Inline stat note -- */
        .stat-note {
            font-family: 'Poppins', Arial, sans-serif;
            font-size: 0.72rem;
            color: var(--mid-gray);
            margin: 0.6rem 0 1rem;
            padding: 0.5rem 0.8rem;
            border-left: 2px solid var(--light-gray);
            text-align: justify;
        }
        .stat-note strong {
            color: var(--dark);
            font-size: 0.68rem;
            text-transform: uppercase;
            letter-spacing: 0.04em;
        }

        /* -- Methodology inline details -- */
        #methodology details:not(.expansion) {
            margin: 0.8rem 0 1.2rem;
            border: 1px solid var(--light-gray);
            border-radius: 6px;
        }
        #methodology details:not(.expansion) > summary {
            font-family: 'Poppins', Arial, sans-serif;
            font-size: 0.75rem;
            font-weight: 500;
            letter-spacing: 0.03em;
            color: var(--blue);
            padding: 0.5rem 1rem;
            cursor: pointer;
            user-select: none;
            list-style: none;
            display: flex;
            align-items: center;
            gap: 0.4rem;
        }
        #methodology details:not(.expansion) > summary::-webkit-details-marker {
            display: none;
        }
        #methodology details:not(.expansion) > summary::before {
            content: '\25B6';
            font-size: 0.6rem;
            transition: transform 0.15s ease;
        }
        #methodology details:not(.expansion)[open] > summary::before {
            transform: rotate(90deg);
        }
        #methodology details:not(.expansion) > summary:hover {
            background: var(--blue-light);
            border-radius: 6px 6px 0 0;
        }
        #methodology details:not(.expansion) > *:not(summary) {
            padding-left: 1rem;
            padding-right: 1rem;
        }
        #methodology details:not(.expansion)[open] > *:nth-child(2) {
            padding-top: 0.75rem;
            border-top: 1px solid var(--light-gray);
        }
        #methodology details:not(.expansion)[open] > *:last-child {
            padding-bottom: 1rem;
        }
        #methodology details:not(.expansion) table {
            font-size: 0.82rem;
        }
        </style>
    </head>
    <body>
        <div class="page">

            <!-- ===== HEADER ===== -->
            <header>
                <div class="eyebrow">Claude Code EAP Report</div>
                <h1>Opus 4.5 &rarr; 4.6: What Changed in Practice?</h1>
                <div class="subtitle">A single-user behavioral study across <!-- var: dataset.total_tasks -->2,320<!-- /var --> Claude Code tasks</div>
                <div class="meta">Samuel H. Christie V &middot; February 2026 &middot; Claude Code Early Access Program</div>
            </header>

            <!-- ===== EXECUTIVE SUMMARY ===== -->
            <section>
                <h2>Executive Summary</h2>

                <div class="stat-row">
                    <div class="stat-card">
                        <div class="label">Per-Task Cost</div>
                        <div class="value v-dark"><!-- var: cost.avg_cost_a -->$2.46<!-- /var --> vs <!-- var: cost.avg_cost_b -->$2.62<!-- /var --></div>
                        <div class="detail">4.6 saves <!-- var: abs((cost.moderate_cost_b / cost.moderate_cost_a - 1) * 100) | .0f -->9<!-- /var -->&ndash;<!-- var: abs((cost.trivial_cost_b / cost.trivial_cost_a - 1) * 100) | .0f -->35<!-- /var -->% at trivial-moderate; +<!-- var: (cost.major_cost_b / cost.major_cost_a - 1) * 100 | .0f -->29<!-- /var -->% at major (&sect;2)</div>
                    </div>
                    <div class="stat-card">
                        <div class="label">Output Token Ratio</div>
                        <div class="value v-blue"><!-- var: cost.avg_output_b / cost.avg_output_a | x.1f -->2.4×<!-- /var --></div>
                        <div class="detail">4.6: <!-- var: cost.avg_output_b -->2,240<!-- /var --> avg vs 4.5: <!-- var: cost.avg_output_a -->953<!-- /var --> avg</div>
                    </div>
                    <div class="stat-card">
                        <div class="label">Tool Calls / Task</div>
                        <div class="value v-blue">+<!-- var: (stat.tool_calls_mean_b / stat.tool_calls_mean_a - 1) * 100 | .0f -->53<!-- /var -->%</div>
                        <div class="detail">Per-task mean <!-- var: stat.tool_calls_mean_b | .1f -->13.4<!-- /var --> vs <!-- var: stat.tool_calls_mean_a | .1f -->8.8<!-- /var --> (incl. subagents: <!-- var: dataset.total_tool_calls_b / dataset.tasks_b | .1f -->16.3<!-- /var --> vs <!-- var: dataset.total_tool_calls_a / dataset.tasks_a | .1f -->10.4<!-- /var -->) (&sect;7)</div>
                    </div>
                    <div class="stat-card">
                        <div class="label">Bonferroni Survivors</div>
                        <div class="value v-dark"><!-- var: stats.overall_bonferroni_count | .0f -->15<!-- /var --> / <!-- var: findings.total_tests | .0f -->529<!-- /var --></div>
                        <div class="detail"><!-- var: stats.overall_bonferroni_count | .0f -->15<!-- /var --> overall; <!-- var: findings.bonferroni_significant | .0f -->93<!-- /var --> including per-complexity and cross-cut strata</div>
                    </div>
                </div>

                <div class="callout" style="border-left:3px solid var(--orange);">
                    <strong>Before you read:</strong> Every number, table, and statistical result in this report is computed directly from analysis data by deterministic Python scripts&mdash;no LLM produces or modifies quantitative claims. LLMs assisted with prose drafting and expression authoring (converting literal numbers to data-bound template variables), but never with fact production. All data comes from a single user&rsquo;s workflow over a limited time period&mdash;treat all findings as anecdotal observations, not generalizable conclusions.
                </div>

                <h3>What Changes When You Switch</h3>

                <p>Across <!-- var: findings.total_tests -->529<!-- /var --> statistical tests (overall, per-complexity, and cross-cut strata), <!-- var: findings.bonferroni_significant -->93<!-- /var --> survive Bonferroni correction&mdash;<!-- var: stats.overall_bonferroni_count | .0f -->15<!-- /var --> at the overall level. Most describe <em>how</em> the model works, not <em>whether</em> it succeeds. The overall success rates are comparable; what changes is the experience of working alongside it. These are the five most noticeable differences, drawn from one user&rsquo;s workflow over <!-- var: dataset.total_tasks -->2,320<!-- /var --> tasks.</p>

                <h3>1. The model plans before it acts&mdash;and you stop steering it</h3>

                <p>Opus 4.6 uses formal planning mode on <!-- var: planning.rate_b | .1f -->13.9<!-- /var -->% of tasks vs <!-- var: planning.rate_a | .1f -->1.7<!-- /var -->% for 4.5, rising to <!-- var: planning.complex_rate_b | .0f -->51<!-- /var -->% at complex and <!-- var: planning.major_rate_b | .0f -->72<!-- /var -->% at major difficulty. It front-loads codebase investigation with a <!-- var: sessions.explore_median_b / sessions.explore_median_a | x.1f -->2.2×<!-- /var --> longer explore phase, deploying subagents that are <!-- var: behavior.explore_count_b / behavior.total_subagents_b * 100 | .0f -->74<!-- /var -->% read-only researchers (vs <!-- var: behavior.explore_count_a / behavior.total_subagents_a * 100 | .0f -->47<!-- /var -->% for 4.5). The practical effect is a shift from interactive collaboration to delegation: you issue a prompt and return to find completed work rather than course-correcting mid-task. This shows up in the data as fewer user-directed corrections across all complexity levels (<a href="#behavior">&sect;4</a>, <a href="#sessions">&sect;8</a>).</p>

                <h3>2. It thinks less often, but more carefully</h3>

                <p>The largest overall effect across all <!-- var: findings.total_tests -->529<!-- /var --> tests is thinking fraction (d=<!-- var: thinking.effect_d -->0.67<!-- /var -->, medium, <a href="#thinking">&sect;3</a>). Opus 4.5 activates extended thinking on <!-- var: cost.thinking_ratio_a | pct -->75%<!-- /var --> of requests regardless of difficulty; 4.6 activates on <!-- var: cost.thinking_ratio_b | pct -->58%<!-- /var --> but averages <!-- var: cost.avg_thinking_when_used_b -->4,175<!-- /var --> characters when it does (vs <!-- var: cost.avg_thinking_when_used_a -->2,635<!-- /var -->). On trivial tasks, 4.6 often skips thinking entirely. On complex tasks, it thinks deeply. This calibration means compute is allocated where it matters rather than spread uniformly across every interaction.</p>

                <h3>3. Fewer rewrites, better first-attempt accuracy</h3>

                <p>Opus 4.6 rewrites its own edits <!-- var: edits.rewrite_rate_b | pct1 -->10.3%<!-- /var --> of the time vs <!-- var: edits.rewrite_rate_a | pct1 -->16.6%<!-- /var -->&mdash;a <!-- var: (1 - edits.rewrite_rate_b / edits.rewrite_rate_a) * 100 | .0f -->38<!-- /var -->% reduction. Its self-correction rate is actually <em>higher</em> (<!-- var: edits.self_correction_b / edits.total_edits_b * 100 | .1f -->3.3<!-- /var -->% vs <!-- var: edits.self_correction_a / edits.total_edits_a * 100 | .1f -->1.9<!-- /var -->%), meaning it catches its own mistakes rather than having the user point them out. Failure rates drop from <!-- var: stat.failed_rate_a * 100 | .1f -->13.2<!-- /var -->% to <!-- var: stat.failed_rate_b * 100 | .1f -->8.6<!-- /var -->%, and alignment scores improve significantly (p=<!-- var: quality.alignment_p -->0.000023<!-- /var -->, one of <!-- var: stats.overall_bonferroni_count | .0f -->15<!-- /var --> overall Bonferroni survivors). The &ldquo;plan first&rdquo; approach appears to pay off in execution accuracy (<a href="#quality">&sect;5</a>, <a href="#edits">&sect;6</a>).</p>

                <h3>4. Sessions get longer&mdash;you trust it with more</h3>

                <p>Median task duration rises <!-- var: (dataset.median_duration_b - dataset.median_duration_a) / dataset.median_duration_a * 100 | .0f -->58<!-- /var -->% (<!-- var: dataset.median_duration_b | .0f -->67<!-- /var -->s vs <!-- var: dataset.median_duration_a | .0f -->42<!-- /var -->s), with fewer ultra-short interactions (<!-- var: dataset.under30s_pct_b | .0f -->34<!-- /var -->% of tasks under 30 seconds vs <!-- var: dataset.under30s_pct_a | .0f -->42<!-- /var -->%). The task mix shifts toward moderate-to-complex work issued in a single instruction, and 4.6 runs more tasks in the background for parallel execution. This isn&rsquo;t purely a model capability difference&mdash;it&rsquo;s a workflow adaptation. When the model handles larger tasks reliably, the user gives it larger tasks, waits longer, and intervenes less. The <!-- var: round(planning.rate_b / planning.rate_a) | .0f -->8<!-- /var -->&times; increase in planning mode (<a href="#behavior">&sect;4</a>) and <!-- var: (stat.tool_calls_mean_b / stat.tool_calls_mean_a - 1) * 100 | .0f -->53<!-- /var -->% more tool calls per task (<a href="#complexity">&sect;7</a>) are partly a consequence of this delegation shift.</p>

                <h3>5. Cost stays flat where it counts</h3>

                <p>Despite <!-- var: cost.avg_output_b / cost.avg_output_a | x.1f -->2.4×<!-- /var --> more output tokens and <!-- var: (stat.tool_calls_mean_b / stat.tool_calls_mean_a - 1) * 100 | .0f -->53<!-- /var -->% more tool calls per task, 4.6 is <!-- var: abs((cost.moderate_cost_b / cost.moderate_cost_a - 1) * 100) | .0f -->9<!-- /var -->&ndash;<!-- var: abs((cost.trivial_cost_b / cost.trivial_cost_a - 1) * 100) | .0f -->35<!-- /var -->% <em>cheaper</em> at trivial through moderate complexity&mdash;the bulk of daily work. The reason is counterintuitive: output tokens account for just <!-- var: max(tokens.cost_output_pct_a, tokens.cost_output_pct_b) | .1f -->6.4<!-- /var -->% of per-task cost, while cache operations account for <!-- var: min(tokens.cost_cache_read_pct_a + tokens.cost_cache_write_pct_a, tokens.cost_cache_read_pct_b + tokens.cost_cache_write_pct_b) | .0f -->94<!-- /var -->&ndash;<!-- var: max(tokens.cost_cache_read_pct_a + tokens.cost_cache_write_pct_a, tokens.cost_cache_read_pct_b + tokens.cost_cache_write_pct_b) | .0f -->97<!-- /var -->%. Opus 4.6 writes <!-- var: (1 - cost.cache_write_b / cost.count_b / (cost.cache_write_a / cost.count_a)) * 100 | .0f -->24<!-- /var -->% less to cache (the most expensive token category at $18.75/MTok), more than offsetting its higher output and cache reads. Cost only tips higher at 30+ API requests, where cumulative cache reads compound past the write savings. Overall per-task cost is <!-- var: cost.avg_cost_b -->$2.62<!-- /var --> vs <!-- var: cost.avg_cost_a -->$2.46<!-- /var -->: functionally neutral for a meaningfully different style of work (<a href="#cost">&sect;2</a>).</p>

                <p>The data is consistent with a tentative characterization: Opus 4.5 acts first and adjusts, while Opus 4.6 investigates first and implements in concentrated bursts. The confounded study design means this framing is a hypothesis, not a conclusion. The analysis was iterative&mdash;several initial findings were revised or reversed when more direct signals became available (<a href="#methodology">&sect;10</a>).</p>
            </section>

            <section id="how-it-works">
                <h2>How This Report Works</h2>

                <p>This report is itself a Claude Code project. The analysis pipeline, statistical tests, table generation, and report assembly are all automated Python scripts, most written with substantial assistance from Opus 4.6&mdash;the same model being evaluated. LLMs are used in two places: task classification (Haiku annotates complexity, sentiment, and task type) and prose drafting. All quantitative claims&mdash;every number, table, and statistical test&mdash;are produced by deterministic computation, not LLM generation. All data comes from one user&rsquo;s real Claude Code sessions during and after the Early Access Program&mdash;not synthetic benchmarks or controlled experiments.</p>

                <div class="pipeline">
                    <div class="pipe-step">Session Logs<small><!-- var: dataset.total_sessions | .0f -->463<!-- /var --> sessions</small></div>
                    <span class="pipe-arrow">&rarr;</span>
                    <div class="pipe-step">Task Extraction<small><!-- var: dataset.total_tasks -->2,320<!-- /var --> tasks</small></div>
                    <span class="pipe-arrow">&rarr;</span>
                    <div class="pipe-step">LLM Classification<small>complexity, sentiment</small></div>
                    <span class="pipe-arrow">&rarr;</span>
                    <div class="pipe-step">Behavioral Analysis<small>edits, planning, subagents</small></div>
                    <span class="pipe-arrow">&rarr;</span>
                    <div class="pipe-step">Token Extraction<small>cost, verbosity</small></div>
                    <span class="pipe-arrow">&rarr;</span>
                    <div class="pipe-step">Statistical Tests<small><!-- var: findings.total_tests | .0f -->529<!-- /var --> comparisons</small></div>
                    <span class="pipe-arrow">&rarr;</span>
                    <div class="pipe-step">Report Build<small>terms, expansions</small></div>
                </div>

                <p>A 12-step pipeline transforms raw JSONL session logs into the finished report. A few things worth noting about the approach:</p>

                <ul>
                    <li><strong>Edit timeline reconstruction:</strong> Rather than relying on LLM self-report, the pipeline builds per-file content ownership maps from every Edit/Write tool call, detecting when later edits overwrite earlier work. This mechanistic signal replaces the sentiment-proxy approach that proved unreliable in early iterations.</li>
                    <li><strong>Multi-signal sentiment:</strong> Dissatisfaction detection combines keyword patterns, structural edit signals (self-corrections, error recoveries), and LLM judgement with downgrade logic&mdash;no single source is trusted alone.</li>
                    <li><strong>Fully computed output:</strong> Every number in this report resolves from analysis JSON via expression-based template variables (<code>{{expr | format}}</code>); every table is generated from spec files. LLMs assist with prose drafting and with converting hardcoded literals into data-bound expressions, but all quantitative claims are produced by deterministic scripts, not LLMs. The pipeline can be re-run end-to-end to reproduce the entire report from raw session logs.</li>
                </ul>

                <h3>What to Trust</h3>

                <p>Numbers, tables, and statistical results are computed deterministically from analysis JSON files and are reproducible by re-running the pipeline. No LLM is in the loop for quantitative claims&mdash;the expression evaluator resolves template variables via pure arithmetic on data paths. Interpretive prose was drafted with LLM assistance and may contain errors or overstatements. Effect sizes and p-values are exact; narrative claims linking those numbers to causal explanations are hypotheses, not conclusions. A <a href="#methodology">sensitivity analysis</a> validates key findings against restricted datasets excluding shared projects. The <a href="#methodology">Methodology section</a> describes every step in full detail.</p>
            </section>

            <nav class="toc">
                <div class="toc-title">Contents &amp; Key Findings</div>
                <div style="padding:0.35rem 0; border-bottom:1px solid var(--light-gray); margin-bottom:0.2rem;">
                    <a href="#how-it-works" style="font-family:'Poppins',sans-serif; font-size:0.82rem; font-weight:500; color:var(--dark); text-decoration:none;">How This Report Works</a>
                    <span class="finding">Pipeline architecture, data provenance, trust calibration</span>
                </div>
                <ol>
                    <li><a href="#dataset">Dataset at a Glance</a><span class="finding"><!-- var: dataset.total_sessions -->463<!-- /var --> sessions, <!-- var: dataset.total_tasks -->2,320<!-- /var --> tasks, <!-- var: dataset.total_projects -->35<!-- /var --> projects, <!-- var: dataset.total_cost -->$7,411<!-- /var --> total cost</span></li>
                    <li><a href="#cost">Token Economy &amp; Cost</a><span class="finding">4.6 <!-- var: abs((cost.moderate_cost_b / cost.moderate_cost_a - 1) * 100) | .0f -->9<!-- /var -->&ndash;<!-- var: abs((cost.trivial_cost_b / cost.trivial_cost_a - 1) * 100) | .0f -->35<!-- /var -->% cheaper trivial&ndash;moderate despite <!-- var: cost.avg_output_b / cost.avg_output_a | x.1f -->2.4×<!-- /var --> output</span></li>
                    <li><a href="#thinking">Thinking &amp; Calibration</a><span class="finding">d=<!-- var: thinking.effect_d -->0.67<!-- /var --> medium effect, #1 overall Bonferroni survivor</span></li>
                    <li><a href="#behavior">Behavioral Patterns</a><span class="finding"><!-- var: round(planning.rate_b / planning.rate_a) | .0f -->8<!-- /var -->&times; planning; <!-- var: behavior.explore_count_b / behavior.total_subagents_b * 100 | .0f -->74<!-- /var -->% read-only Explore; effort front-loading</span></li>
                    <li><a href="#quality">Quality &amp; Satisfaction</a><span class="finding">Alignment survives Bonferroni; 4.6 fails less (<!-- var: stat.failed_rate_b * 100 | .1f -->8.6<!-- /var -->% vs <!-- var: stat.failed_rate_a * 100 | .1f -->13.2<!-- /var -->%)</span></li>
                    <li><a href="#edits">Edit Accuracy</a><span class="finding">4.6 rewrites <!-- var: edits.rewrite_rate_b | pct1 -->10.3%<!-- /var --> vs <!-- var: edits.rewrite_rate_a | pct1 -->16.6%<!-- /var --></span></li>
                    <li><a href="#complexity">Complexity &amp; Resource Usage</a><span class="finding">Tool calls strongest signal (p&lt;0.000001, d=<!-- var: -1 * stat.tool_calls_d | .2f -->0.29<!-- /var -->)</span></li>
                    <li><a href="#sessions">Session Dynamics</a><span class="finding"><!-- var: sessions.explore_median_b / sessions.explore_median_a | x.1f -->2.2×<!-- /var --> explore phase; compaction preserves not degrades</span></li>
                    <li><a href="#profiles">Model Profiles</a><span class="finding">Observed behavioral patterns (not routing recommendations)</span></li>
                    <li><a href="#methodology">Methodology</a><span class="finding"><!-- var: findings.total_tests -->529<!-- /var --> tests, sensitivity-validated</span></li>
                </ol>
            </nav>

<!-- ===== 1. DATASET AT A GLANCE ===== -->
            <section id="dataset">
                <h2>1. Dataset at a Glance</h2>

                <div class="stat-row">
                    <div class="stat-card">
                        <div class="label">Sessions Analyzed</div>
                        <div class="value v-dark"><!-- var: dataset.total_sessions -->463<!-- /var --></div>
                        <div class="detail"><!-- var: dataset.sessions_a -->327<!-- /var --> (4.5) + <!-- var: dataset.sessions_b -->136<!-- /var --> (4.6)</div>
                    </div>
                    <div class="stat-card">
                        <div class="label">Tasks Extracted</div>
                        <div class="value v-dark"><!-- var: dataset.total_tasks -->2,320<!-- /var --></div>
                        <div class="detail"><!-- var: dataset.tasks_a -->1,729<!-- /var --> (4.5) + <!-- var: dataset.tasks_b -->591<!-- /var --> (4.6)</div>
                    </div>
                    <div class="stat-card">
                        <div class="label">Projects Spanned</div>
                        <div class="value v-dark"><!-- var: dataset.total_projects -->35<!-- /var --></div>
                        <div class="detail"><!-- var: dataset.projects_a + dataset.projects_b - dataset.total_projects | .0f -->9<!-- /var --> shared between both models</div>
                    </div>
                    <div class="stat-card">
                        <div class="label">Total API Cost</div>
                        <div class="value v-dark"><!-- var: dataset.total_cost -->$7,411<!-- /var --></div>
                        <div class="detail"><!-- var: dataset.cost_a -->$5,292<!-- /var --> (4.5) + <!-- var: dataset.cost_b -->$2,119<!-- /var --> (4.6)</div>
                    </div>
                </div>

                <p>All data comes from a single user's organic Claude Code sessions between December 2025 and February 2026. The dataset is intentionally asymmetric: Opus 4.5 served as the primary model for two months, while Opus 4.6 entered evaluation in early February. This means Opus 4.5 totals are larger in absolute terms, but per-task and per-session comparisons normalize for this. Where sample size limits statistical power, the report notes it explicitly.</p>

                <p>The 9-day concentration of the Opus 4.6 data creates a temporal clustering concern: a productive stretch, a particular project focus, or simply the novelty of a new model could color all <!-- var: dataset.tasks_b | .0f -->591<!-- /var --> tasks simultaneously. The report treats tasks as independent observations, but short collection windows make this assumption weaker for 4.6 than for 4.5&rsquo;s two-month span.</p>

                <!-- expand: dataset-composition -->
                <!-- expand: dataset-task-mix -->
                <!-- expand: dataset-volume -->

                <p>With the dataset in view, we turn to what the token data reveals about how each model allocates its computational budget.</p>
            </section>

<!-- ===== 2. TOKEN ECONOMY &amp; COST ===== -->
            <section id="cost"><h2>2. Token Economy &amp; Cost</h2>

                <p>Opus 4.6 costs ~<!-- var: (cost.avg_cost_b / cost.avg_cost_a - 1) * 100 | .1f -->6.8<!-- /var -->% more per task on average (<!-- var: cost.avg_cost_b -->$2.62<!-- /var --> vs <!-- var: cost.avg_cost_a -->$2.46<!-- /var -->), despite producing <!-- var: cost.avg_output_b / cost.avg_output_a | x.1f -->2.4×<!-- /var --> more output tokens and making more API round-trips (<!-- var: cost.avg_requests_b -->9.6<!-- /var --> vs <!-- var: cost.avg_requests_a -->7.5<!-- /var --> requests/task). But this aggregate masks a complexity-dependent pattern: at trivial through moderate levels, 4.6 is <!-- var: abs((cost.moderate_cost_b / cost.moderate_cost_a - 1) * 100) | .0f -->9<!-- /var -->&ndash;<!-- var: abs((cost.trivial_cost_b / cost.trivial_cost_a - 1) * 100) | .0f -->35<!-- /var -->% <em>cheaper</em>, driven by superior cache economics&mdash;not output efficiency. Output tokens account for less than <!-- var: max(tokens.cost_output_pct_a, tokens.cost_output_pct_b) | .0f -->6<!-- /var -->% of per-task cost; cache operations account for ~<!-- var: min(tokens.cost_cache_read_pct_a + tokens.cost_cache_write_pct_a, tokens.cost_cache_read_pct_b + tokens.cost_cache_write_pct_b) | .0f -->94<!-- /var -->%. 4.6 achieves a leaner cache footprint, writing <!-- var: (1 - cost.cache_write_b / cost.count_b / (cost.cache_write_a / cost.count_a)) * 100 | .0f -->24<!-- /var -->% fewer tokens at the most expensive token category. The cost advantage reverses at complex and major tiers, where accumulated cache reads over many requests outweigh the write savings.</p>

                <div class="stat-row">
                    <div class="stat-card">
                        <div class="label">Per-Task Cost</div>
                        <div class="value v-dark"><!-- var: cost.avg_cost_a -->$2.46<!-- /var --> vs <!-- var: cost.avg_cost_b -->$2.62<!-- /var --></div>
                        <div class="detail">4.6 is ~<!-- var: (cost.avg_cost_b / cost.avg_cost_a - 1) * 100 | .1f -->6.8<!-- /var -->% more expensive overall; cheaper at trivial&ndash;moderate</div>
                    </div>
                    <div class="stat-card">
                        <div class="label">Output Token Ratio</div>
                        <div class="value v-blue"><!-- var: cost.avg_output_b / cost.avg_output_a | x.1f -->2.4×<!-- /var --></div>
                        <div class="detail">4.6 produces <!-- var: cost.avg_output_b -->2,240<!-- /var --> vs <!-- var: cost.avg_output_a -->953<!-- /var --> avg tokens</div>
                    </div>
                    <div class="stat-card">
                        <div class="label">Per-Request Output</div>
                        <div class="value v-blue"><!-- var: cost.avg_output_per_request_b / cost.avg_output_per_request_a | x.1f -->1.8×<!-- /var --></div>
                        <div class="detail"><!-- var: cost.avg_output_per_request_b -->233<!-- /var --> vs <!-- var: cost.avg_output_per_request_a -->128<!-- /var --> tokens/request</div>
                    </div>
                </div>

                <h3>Output Verbosity by Task Type</h3>

<!-- GENERATED-TABLE: cost-verbosity-by-type -->
<table>
    <thead>
        <tr><th>Task Type</th><th>Output Comparison</th><th class="right">4.5 avg</th><th class="right">4.6 avg</th><th class="right">4.6/4.5</th></tr>
    </thead>
    <tbody>
        <tr><td class="label-cell">Greenfield</td>
            <td class="bar-cell"><div class="bar-pair">
                <div class="bar-row"><span class="bar-tag">A</span><div class="bar-track"><div class="bar-fill a" style="width:17.5%"></div><div class="bar-ci" style="left:9.3%;width:18.5%" title="95% CI: [974.8, 2915.9]"></div></div><span class="bar-val">1,839</span></div>
                <div class="bar-row"><span class="bar-tag">B</span><div class="bar-track"><div class="bar-fill b" style="width:70.3%"></div><div class="bar-ci" style="left:43.5%;width:56.5%" title="95% CI: [4566.0, 10506.5]"></div></div><span class="bar-val">7,389</span></div>
            </div></td>
            <td class="right mono">1,839</td><td class="right mono">7,389</td><td class="right mono v-blue">4.0&times;</td></tr>
        <tr><td class="label-cell">Refactor</td>
            <td class="bar-cell"><div class="bar-pair">
                <div class="bar-row"><span class="bar-tag">A</span><div class="bar-track"><div class="bar-fill a" style="width:12.5%"></div><div class="bar-ci" style="left:6.8%;width:12.6%" title="95% CI: [713.7, 2038.3]"></div></div><span class="bar-val">1,310</span></div>
                <div class="bar-row"><span class="bar-tag">B</span><div class="bar-track"><div class="bar-fill b" style="width:54.0%"></div><div class="bar-ci" style="left:31.3%;width:48.9%" title="95% CI: [3284.5, 8417.1]"></div></div><span class="bar-val">5,670</span></div>
            </div></td>
            <td class="right mono">1,310</td><td class="right mono">5,670</td><td class="right mono v-blue">4.3&times;</td></tr>
        <tr><td class="label-cell">Bugfix</td>
            <td class="bar-cell"><div class="bar-pair">
                <div class="bar-row"><span class="bar-tag">A</span><div class="bar-track"><div class="bar-fill a" style="width:7.9%"></div><div class="bar-ci" style="left:4.2%;width:8.7%" title="95% CI: [439.3, 1353.5]"></div></div><span class="bar-val">825</span></div>
                <div class="bar-row"><span class="bar-tag">B</span><div class="bar-track"><div class="bar-fill b" style="width:41.0%"></div><div class="bar-ci" style="left:22.1%;width:43.8%" title="95% CI: [2320.8, 6922.5]"></div></div><span class="bar-val">4,311</span></div>
            </div></td>
            <td class="right mono">825</td><td class="right mono">4,311</td><td class="right mono v-blue">5.2&times;</td></tr>
        <tr><td class="label-cell">Feature</td>
            <td class="bar-cell"><div class="bar-pair">
                <div class="bar-row"><span class="bar-tag">A</span><div class="bar-track"><div class="bar-fill a" style="width:15.8%"></div><div class="bar-ci" style="left:9.4%;width:14.5%" title="95% CI: [983.4, 2510.1]"></div></div><span class="bar-val">1,664</span></div>
                <div class="bar-row"><span class="bar-tag">B</span><div class="bar-track"><div class="bar-fill b" style="width:30.3%"></div><div class="bar-ci" style="left:17.9%;width:27.8%" title="95% CI: [1883.8, 4805.3]"></div></div><span class="bar-val">3,184</span></div>
            </div></td>
            <td class="right mono">1,664</td><td class="right mono">3,184</td><td class="right mono">1.9&times;</td></tr>
        <tr><td class="label-cell">Investigation</td>
            <td class="bar-cell"><div class="bar-pair">
                <div class="bar-row"><span class="bar-tag">A</span><div class="bar-track"><div class="bar-fill a" style="width:9.7%"></div><div class="bar-ci" style="left:7.4%;width:5.0%" title="95% CI: [776.1, 1298.4]"></div></div><span class="bar-val">1,024</span></div>
                <div class="bar-row"><span class="bar-tag">B</span><div class="bar-track"><div class="bar-fill b" style="width:23.0%"></div><div class="bar-ci" style="left:16.8%;width:13.7%" title="95% CI: [1766.3, 3208.5]"></div></div><span class="bar-val">2,415</span></div>
            </div></td>
            <td class="right mono">1,024</td><td class="right mono">2,415</td><td class="right mono v-blue">2.4&times;</td></tr>
        <tr><td class="label-cell">Port</td>
            <td class="bar-cell"><div class="bar-pair">
                <div class="bar-row"><span class="bar-tag">A</span><div class="bar-track"><div class="bar-fill a" style="width:23.4%"></div><div class="bar-ci" style="left:6.9%;width:37.9%" title="95% CI: [726.1, 4712.9]"></div></div><span class="bar-val">2,460</span></div>
                <div class="bar-row"><span class="bar-tag">B</span><div class="bar-track"><div class="bar-fill b" style="width:32.8%"></div><div class="bar-ci" style="left:12.2%;width:43.9%" title="95% CI: [1284.5, 5892.9]"></div></div><span class="bar-val">3,443</span></div>
            </div></td>
            <td class="right mono">2,460</td><td class="right mono">3,443</td><td class="right mono">1.4&times;</td></tr>
        <tr><td class="label-cell">Continuation</td>
            <td class="bar-cell"><div class="bar-pair">
                <div class="bar-row"><span class="bar-tag">A</span><div class="bar-track"><div class="bar-fill a" style="width:12.1%"></div><div class="bar-ci" style="left:3.8%;width:19.2%" title="95% CI: [394.1, 2406.4]"></div></div><span class="bar-val">1,272</span></div>
                <div class="bar-row"><span class="bar-tag">B</span><div class="bar-track"><div class="bar-fill b" style="width:22.2%"></div><div class="bar-ci" style="left:9.8%;width:29.8%" title="95% CI: [1030.9, 4165.1]"></div></div><span class="bar-val">2,329</span></div>
            </div></td>
            <td class="right mono">1,272</td><td class="right mono">2,329</td><td class="right mono">1.8&times;</td></tr>
        <tr><td class="label-cell">Sysadmin</td>
            <td class="bar-cell"><div class="bar-pair">
                <div class="bar-row"><span class="bar-tag">A</span><div class="bar-track"><div class="bar-fill a" style="width:5.7%"></div><div class="bar-ci" style="left:3.1%;width:5.9%" title="95% CI: [330.4, 947.6]"></div></div><span class="bar-val">595</span></div>
                <div class="bar-row"><span class="bar-tag">B</span><div class="bar-track"><div class="bar-fill b" style="width:8.1%"></div><div class="bar-ci" style="left:5.0%;width:7.3%" title="95% CI: [520.6, 1288.9]"></div></div><span class="bar-val">852</span></div>
            </div></td>
            <td class="right mono">595</td><td class="right mono">852</td><td class="right mono">1.4&times;</td></tr>
        <tr><td class="label-cell">Docs</td>
            <td class="bar-cell"><div class="bar-pair">
                <div class="bar-row"><span class="bar-tag">A</span><div class="bar-track"><div class="bar-fill a" style="width:3.2%"></div><div class="bar-ci" style="left:2.1%;width:2.3%" title="95% CI: [218.3, 460.5]"></div></div><span class="bar-val">331</span></div>
                <div class="bar-row"><span class="bar-tag">B</span><div class="bar-track"><div class="bar-fill b" style="width:6.3%"></div><div class="bar-ci" style="left:2.4%;width:8.5%" title="95% CI: [253.6, 1142.2]"></div></div><span class="bar-val">659</span></div>
            </div></td>
            <td class="right mono">331</td><td class="right mono">659</td><td class="right mono">2.0&times;</td></tr>
    </tbody>
</table>
<!-- /GENERATED-TABLE: cost-verbosity-by-type -->

                <p>The <!-- var: tokens.refactor_output_b / tokens.refactor_output_a | x.1f -->4.3×<!-- /var --> ratio for refactoring is notable: Opus 4.6 produces substantially more output tokens for refactoring tasks, suggesting more thorough changes. For continuation tasks (follow-ups within a session), Opus 4.6 produces <!-- var: tokens.continuation_output_b / tokens.continuation_output_a | x.1f -->1.8×<!-- /var --> the output volume of Opus 4.5.</p>

                <h3>Cost by Complexity</h3>

<!-- GENERATED-TABLE: cost-by-complexity-inline -->
<table>
    <thead>
        <tr><th>Complexity</th><th>Cost Comparison</th><th class="right">4.5 avg cost</th><th class="right">4.6 avg cost</th><th class="right">&Delta;</th></tr>
    </thead>
    <tbody>
        <tr><td class="label-cell">Trivial</td>
            <td class="bar-cell"><div class="bar-pair">
                <div class="bar-row"><span class="bar-tag">A</span><div class="bar-track"><div class="bar-fill a" style="width:4.3%"></div><div class="bar-ci" style="left:3.9%;width:0.9%" title="95% CI: [0.8, 1.0]"></div></div><span class="bar-val">$0.86</span></div>
                <div class="bar-row"><span class="bar-tag">B</span><div class="bar-track"><div class="bar-fill b" style="width:2.8%"></div><div class="bar-ci" style="left:2.3%;width:1.2%" title="95% CI: [0.5, 0.7]"></div></div><span class="bar-val">$0.56</span></div>
            </div></td>
            <td class="right mono">$0.86</td><td class="right mono">$0.56</td><td class="right mono v-green">&minus;35%</td></tr>
        <tr><td class="label-cell">Simple</td>
            <td class="bar-cell"><div class="bar-pair">
                <div class="bar-row"><span class="bar-tag">A</span><div class="bar-track"><div class="bar-fill a" style="width:11.3%"></div><div class="bar-ci" style="left:10.2%;width:2.1%" title="95% CI: [2.0, 2.4]"></div></div><span class="bar-val">$2.24</span></div>
                <div class="bar-row"><span class="bar-tag">B</span><div class="bar-track"><div class="bar-fill b" style="width:8.1%"></div><div class="bar-ci" style="left:6.9%;width:2.8%" title="95% CI: [1.4, 1.9]"></div></div><span class="bar-val">$1.62</span></div>
            </div></td>
            <td class="right mono">$2.24</td><td class="right mono">$1.62</td><td class="right mono v-green">&minus;28%</td></tr>
        <tr><td class="label-cell">Moderate</td>
            <td class="bar-cell"><div class="bar-pair">
                <div class="bar-row"><span class="bar-tag">A</span><div class="bar-track"><div class="bar-fill a" style="width:17.7%"></div><div class="bar-ci" style="left:16.5%;width:2.5%" title="95% CI: [3.3, 3.8]"></div></div><span class="bar-val">$3.52</span></div>
                <div class="bar-row"><span class="bar-tag">B</span><div class="bar-track"><div class="bar-fill b" style="width:16.1%"></div><div class="bar-ci" style="left:14.6%;width:3.1%" title="95% CI: [2.9, 3.5]"></div></div><span class="bar-val">$3.19</span></div>
            </div></td>
            <td class="right mono">$3.52</td><td class="right mono">$3.19</td><td class="right mono v-green">&minus;9%</td></tr>
        <tr><td class="label-cell">Complex</td>
            <td class="bar-cell"><div class="bar-pair">
                <div class="bar-row"><span class="bar-tag">A</span><div class="bar-track"><div class="bar-fill a" style="width:36.5%"></div><div class="bar-ci" style="left:33.7%;width:5.7%" title="95% CI: [6.7, 7.8]"></div></div><span class="bar-val">$7.25</span></div>
                <div class="bar-row"><span class="bar-tag">B</span><div class="bar-track"><div class="bar-fill b" style="width:36.9%"></div><div class="bar-ci" style="left:32.8%;width:8.3%" title="95% CI: [6.5, 8.2]"></div></div><span class="bar-val">$7.32</span></div>
            </div></td>
            <td class="right mono">$7.25</td><td class="right mono">$7.32</td><td class="right mono v-orange">+1%</td></tr>
        <tr><td class="label-cell">Major</td>
            <td class="bar-cell"><div class="bar-pair">
                <div class="bar-row"><span class="bar-tag">A</span><div class="bar-track"><div class="bar-fill a" style="width:63.0%"></div><div class="bar-ci" style="left:46.6%;width:36.9%" title="95% CI: [9.3, 16.6]"></div></div><span class="bar-val">$12.51</span></div>
                <div class="bar-row"><span class="bar-tag">B</span><div class="bar-track"><div class="bar-fill b" style="width:81.5%"></div><div class="bar-ci" style="left:63.1%;width:36.9%" title="95% CI: [12.5, 19.8]"></div></div><span class="bar-val">$16.18</span></div>
            </div></td>
            <td class="right mono">$12.51</td><td class="right mono">$16.18</td><td class="right mono v-orange">+29%</td></tr>
    </tbody>
</table>
<!-- /GENERATED-TABLE: cost-by-complexity-inline -->

                <h3>Session-Hour Cost</h3>
                <p>Normalizing by session hours rather than task count: Opus 4.5 costs $<!-- var: dataset.cost_a / dataset.session_hours_a | .2f -->12.75<!-- /var -->/session-hour (<!-- var: dataset.cost_a -->$5,292<!-- /var --> over <!-- var: dataset.session_hours_a -->415.2<!-- /var -->h) vs $<!-- var: dataset.cost_b / dataset.session_hours_b | .2f -->6.82<!-- /var -->/session-hour for Opus 4.6 (<!-- var: dataset.cost_b -->$2,119<!-- /var --> over <!-- var: dataset.session_hours_b -->310.9<!-- /var -->h). Session hours measure wall-clock time from first to last message, so this metric includes idle time and is not a direct measure of active coding cost.</p>

                <div class="callout green">
                    <strong>Cost pattern (with caveats):</strong> Despite producing <!-- var: cost.avg_output_b / cost.avg_output_a | x.1f -->2.4×<!-- /var --> more output and costing ~<!-- var: (cost.avg_cost_b / cost.avg_cost_a - 1) * 100 | .1f -->6.8<!-- /var -->% more per task overall, Opus 4.6 is <!-- var: abs((cost.moderate_cost_b / cost.moderate_cost_a - 1) * 100) | .0f -->9<!-- /var -->&ndash;<!-- var: abs((cost.trivial_cost_b / cost.trivial_cost_a - 1) * 100) | .0f -->35<!-- /var -->% <em>cheaper</em> at trivial through moderate complexity. The explanation is structural: output accounts for just <!-- var: max(tokens.cost_output_pct_a, tokens.cost_output_pct_b) | .0f -->6<!-- /var -->% of cost while cache operations account for <!-- var: min(tokens.cost_cache_read_pct_a + tokens.cost_cache_write_pct_a, tokens.cost_cache_read_pct_b + tokens.cost_cache_write_pct_b) | .0f -->94<!-- /var -->&ndash;<!-- var: max(tokens.cost_cache_read_pct_a + tokens.cost_cache_write_pct_a, tokens.cost_cache_read_pct_b + tokens.cost_cache_write_pct_b) | .0f -->97<!-- /var -->%, and 4.6 writes <!-- var: (1 - cost.cache_write_b / cost.count_b / (cost.cache_write_a / cost.count_a)) * 100 | .0f -->24<!-- /var -->% less to cache (the most expensive token category at $18.75/MTok). At major tiers, accumulated cache reads over 30+ requests exceed the write savings (+<!-- var: (cost.major_cost_b / cost.major_cost_a - 1) * 100 | .0f -->29<!-- /var -->%), but this is based on <!-- var: cost.major_count_b | .0f -->18<!-- /var --> vs <!-- var: cost.major_count_a | .0f -->19<!-- /var --> tasks. These figures come from organic sessions where task mix and session structure differ between models.
                </div>

                <h3>Per-Request Output</h3>

<!-- GENERATED-TABLE: per-request-output -->
<table>
    <thead>
        <tr><th>Complexity</th><th>Output per Request</th><th class="right">4.5</th><th class="right">4.6</th><th class="right">Ratio</th></tr>
    </thead>
    <tbody>
        <tr><td class="label-cell">Trivial</td>
            <td class="bar-cell"><div class="bar-pair">
                <div class="bar-row"><span class="bar-tag">A</span><div class="bar-track"><div class="bar-fill a" style="width:13.5%"></div><div class="bar-ci" style="left:9.4%;width:5.2%" title="95% CI: [43.3, 67.2]"></div></div><span class="bar-val">62</span></div>
                <div class="bar-row"><span class="bar-tag">B</span><div class="bar-track"><div class="bar-fill b" style="width:22.8%"></div><div class="bar-ci" style="left:14.5%;width:11.0%" title="95% CI: [66.9, 117.2]"></div></div><span class="bar-val">105</span></div>
            </div></td>
            <td class="right mono">62</td><td class="right mono">105</td><td class="right mono v-blue">1.7&times;</td></tr>
        <tr><td class="label-cell">Simple</td>
            <td class="bar-cell"><div class="bar-pair">
                <div class="bar-row"><span class="bar-tag">A</span><div class="bar-track"><div class="bar-fill a" style="width:19.6%"></div><div class="bar-ci" style="left:18.3%;width:7.7%" title="95% CI: [84.3, 119.7]"></div></div><span class="bar-val">90</span></div>
                <div class="bar-row"><span class="bar-tag">B</span><div class="bar-track"><div class="bar-fill b" style="width:30.9%"></div><div class="bar-ci" style="left:26.2%;width:16.5%" title="95% CI: [120.6, 196.5]"></div></div><span class="bar-val">142</span></div>
            </div></td>
            <td class="right mono">90</td><td class="right mono">142</td><td class="right mono v-blue">1.6&times;</td></tr>
        <tr><td class="label-cell">Moderate</td>
            <td class="bar-cell"><div class="bar-pair">
                <div class="bar-row"><span class="bar-tag">A</span><div class="bar-track"><div class="bar-fill a" style="width:28.7%"></div><div class="bar-ci" style="left:29.4%;width:14.3%" title="95% CI: [135.4, 201.1]"></div></div><span class="bar-val">132</span></div>
                <div class="bar-row"><span class="bar-tag">B</span><div class="bar-track"><div class="bar-fill b" style="width:47.2%"></div><div class="bar-ci" style="left:45.4%;width:17.8%" title="95% CI: [208.5, 290.5]"></div></div><span class="bar-val">217</span></div>
            </div></td>
            <td class="right mono">132</td><td class="right mono">217</td><td class="right mono v-blue">1.6&times;</td></tr>
        <tr><td class="label-cell">Complex</td>
            <td class="bar-cell"><div class="bar-pair">
                <div class="bar-row"><span class="bar-tag">A</span><div class="bar-track"><div class="bar-fill a" style="width:32.2%"></div><div class="bar-ci" style="left:32.0%;width:24.9%" title="95% CI: [147.1, 261.5]"></div></div><span class="bar-val">148</span></div>
                <div class="bar-row"><span class="bar-tag">B</span><div class="bar-track"><div class="bar-fill b" style="width:68.9%"></div><div class="bar-ci" style="left:60.4%;width:39.6%" title="95% CI: [277.9, 459.8]"></div></div><span class="bar-val">317</span></div>
            </div></td>
            <td class="right mono">148</td><td class="right mono">317</td><td class="right mono v-blue">2.1&times;</td></tr>
        <tr><td class="label-cell">Major</td>
            <td class="bar-cell"><div class="bar-pair">
                <div class="bar-row"><span class="bar-tag">A</span><div class="bar-track"><div class="bar-fill a" style="width:35.0%"></div><div class="bar-ci" style="left:9.9%;width:74.3%" title="95% CI: [45.6, 387.3]"></div></div><span class="bar-val">161</span></div>
                <div class="bar-row"><span class="bar-tag">B</span><div class="bar-track"><div class="bar-fill b" style="width:52.4%"></div><div class="bar-ci" style="left:38.7%;width:30.8%" title="95% CI: [177.9, 319.6]"></div></div><span class="bar-val">241</span></div>
            </div></td>
            <td class="right mono">161</td><td class="right mono">241</td><td class="right mono">1.5&times;</td></tr>
    </tbody>
</table>
<!-- /GENERATED-TABLE: per-request-output -->

                <p>Per-request output survives Bonferroni correction (d=<!-- var: stat.output_per_request_d | .2f -->-0.33<!-- /var -->, small). Opus 4.6 produces more tokens per API round-trip at every complexity level, concentrating work into larger responses rather than many small incremental calls.</p>

                <h3>Why Output Doesn&rsquo;t Drive Cost</h3>

                <p>The <!-- var: cost.avg_output_b / cost.avg_output_a | x.1f -->2.4×<!-- /var --> output difference seems like it should dominate the cost comparison, but output tokens are a minor cost component. Cache operations dwarf everything else:</p>

                <table>
                    <thead>
                        <tr><th>Component</th><th class="right">Price/MTok</th><th class="right">4.5/task</th><th class="right">4.5 cost</th><th class="right">4.6/task</th><th class="right">4.6 cost</th><th class="right">% of total</th></tr>
                    </thead>
                    <tbody>
                        <tr><td class="label-cell">Input</td><td class="right mono">$15.00</td><td class="right mono"><!-- var: cost.avg_input_a | .0f -->314<!-- /var --></td><td class="right mono">$<!-- var: cost.avg_input_a * 15 / 1000000 | .3f -->0.005<!-- /var --></td><td class="right mono"><!-- var: cost.avg_input_b | .0f -->146<!-- /var --></td><td class="right mono">$<!-- var: cost.avg_input_b * 15 / 1000000 | .3f -->0.002<!-- /var --></td><td class="right mono">&lt;1%</td></tr>
                        <tr><td class="label-cell">Output</td><td class="right mono">$75.00</td><td class="right mono"><!-- var: cost.avg_output_a -->953<!-- /var --></td><td class="right mono">$<!-- var: cost.avg_output_a * 75 / 1000000 | .3f -->0.071<!-- /var --></td><td class="right mono"><!-- var: cost.avg_output_b -->2,240<!-- /var --></td><td class="right mono">$<!-- var: cost.avg_output_b * 75 / 1000000 | .3f -->0.168<!-- /var --></td><td class="right mono">3&ndash;6%</td></tr>
                        <tr><td class="label-cell">Cache read</td><td class="right mono">$1.875</td><td class="right mono"><!-- var: cost.cache_read_a / cost.count_a / 1000 | .0f -->594<!-- /var -->K</td><td class="right mono">$<!-- var: cost.cache_read_a / cost.count_a * 1.875 / 1000000 | .2f -->1.11<!-- /var --></td><td class="right mono"><!-- var: cost.cache_read_b / cost.count_b / 1000 | .0f -->794<!-- /var -->K</td><td class="right mono">$<!-- var: cost.cache_read_b / cost.count_b * 1.875 / 1000000 | .2f -->1.49<!-- /var --></td><td class="right mono">45&ndash;57%</td></tr>
                        <tr><td class="label-cell">Cache write</td><td class="right mono">$18.75</td><td class="right mono"><!-- var: cost.cache_write_a / cost.count_a / 1000 | .0f -->68<!-- /var -->K</td><td class="right mono">$<!-- var: cost.cache_write_a / cost.count_a * 18.75 / 1000000 | .2f -->1.27<!-- /var --></td><td class="right mono"><!-- var: cost.cache_write_b / cost.count_b / 1000 | .0f -->51<!-- /var -->K</td><td class="right mono">$<!-- var: cost.cache_write_b / cost.count_b * 18.75 / 1000000 | .2f -->0.96<!-- /var --></td><td class="right mono">37&ndash;52%</td></tr>
                        <tr style="font-weight:600"><td class="label-cell">Total</td><td></td><td></td><td class="right mono"><!-- var: cost.avg_cost_a -->$2.46<!-- /var --></td><td></td><td class="right mono"><!-- var: cost.avg_cost_b -->$2.62<!-- /var --></td><td></td></tr>
                    </tbody>
                </table>

                <p>Three forces offset to produce the $<!-- var: cost.avg_cost_b - cost.avg_cost_a | .2f -->0.17<!-- /var --> net difference. 4.6 writes <!-- var: (1 - cost.cache_write_b / cost.count_b / (cost.cache_write_a / cost.count_a)) * 100 | .0f -->24<!-- /var -->% fewer tokens to cache per task (<!-- var: cost.cache_write_b / cost.count_b / 1000 | .0f -->51<!-- /var -->K vs <!-- var: cost.cache_write_a / cost.count_a / 1000 | .0f -->68<!-- /var -->K), saving $<!-- var: (cost.cache_write_a / cost.count_a - cost.cache_write_b / cost.count_b) * 18.75 / 1000000 | .2f -->0.30<!-- /var --> at the most expensive category ($18.75/M&mdash;10&times; the read price). But 4.6 reads <!-- var: (cost.cache_read_b / cost.count_b / (cost.cache_read_a / cost.count_a) - 1) * 100 | .0f -->34<!-- /var -->% more cached context (<!-- var: cost.cache_read_b / cost.count_b / 1000 | .0f -->794<!-- /var -->K vs <!-- var: cost.cache_read_a / cost.count_a / 1000 | .0f -->594<!-- /var -->K), costing $<!-- var: (cost.cache_read_b / cost.count_b - cost.cache_read_a / cost.count_a) * 1.875 / 1000000 | .2f -->0.38<!-- /var --> at the cheapest category ($1.875/M). And the <!-- var: cost.avg_output_b / cost.avg_output_a | x.1f -->2.4×<!-- /var --> output increase costs only $<!-- var: (cost.avg_output_b - cost.avg_output_a) * 75 / 1000000 | .2f -->0.10<!-- /var -->. The write savings nearly cancel the read and output increases: &minus;$<!-- var: (cost.cache_write_a / cost.count_a - cost.cache_write_b / cost.count_b) * 18.75 / 1000000 | .2f -->0.30<!-- /var --> + $<!-- var: (cost.cache_read_b / cost.count_b - cost.cache_read_a / cost.count_a) * 1.875 / 1000000 | .2f -->0.38<!-- /var --> + $<!-- var: (cost.avg_output_b - cost.avg_output_a) * 75 / 1000000 | .2f -->0.10<!-- /var --> = +$<!-- var: cost.avg_cost_b - cost.avg_cost_a | .2f -->0.17<!-- /var -->.</p>

                <p><em>Why</em> does 4.6 write less to cache? Per-request analysis reveals two mechanisms. First, 4.6 starts tasks with a leaner cache footprint&mdash;its first API request writes <!-- var: (1 - tokens.cold_first_write_b / tokens.cold_first_write_a) * 100 | .0f -->43<!-- /var -->% fewer cache tokens than 4.5&rsquo;s, suggesting a more compact or reusable context structure. Second, when cache cools (gap &gt;5 minutes between tasks), both models experience cold starts at identical rates (~25% of transitions), but 4.5 must re-write 177K tokens to repopulate vs 87K for 4.6. Cold cache causes a 6.4&times; write inflation for 4.5 but only 2.1&times; for 4.6. The likely explanation: 4.6&rsquo;s &ldquo;investigate then execute&rdquo; pattern creates more compact, reusable context, while 4.5&rsquo;s incremental approach builds a larger accumulated context that costs more to re-cache after cooling.</p>

                <p>This mechanism produces the complexity-dependent curve above. At trivial through moderate tiers (typically &le;30 API requests), lean initialization dominates and 4.6 is <!-- var: abs((cost.moderate_cost_b / cost.moderate_cost_a - 1) * 100) | .0f -->9<!-- /var -->&ndash;<!-- var: abs((cost.trivial_cost_b / cost.trivial_cost_a - 1) * 100) | .0f -->35<!-- /var -->% cheaper. At 30+ requests, cumulative cache reads compound past the initialization savings&mdash;4.6&rsquo;s per-request cache reads are slightly higher (89K vs 80K in the 30+ tier), and spread over 50+ requests, this adds up.</p>

                <!-- expand: cost-cache-analysis -->

                <!-- expand: cost-cache-efficiency -->

                <!-- expand: cost-by-complexity -->

                <h3>Cross-Cut Detail</h3>
                <!-- expand: findings-cost -->

                <p>The cost difference raises a natural question: does 4.6&rsquo;s different spending pattern correspond to different thinking strategies? The next section examines thinking calibration&mdash;the largest overall effect in the study.</p>
            </section>

            <!-- ===== 3. THINKING & CALIBRATION ===== -->
            <section id="thinking">
                <h2>3. Thinking &amp; Calibration</h2>

                <div class="stat-row">
                    <div class="stat-card">
                        <div class="label">Thinking Fraction Effect</div>
                        <div class="value v-blue">d=<!-- var: thinking.effect_d -->0.67<!-- /var --></div>
                        <div class="detail">#1 overall Bonferroni survivor (medium)</div>
                    </div>
                    <div class="stat-card">
                        <div class="label">Thinking Frequency</div>
                        <div class="value v-dark"><!-- var: cost.thinking_ratio_a -->75%<!-- /var --> vs <!-- var: cost.thinking_ratio_b -->58%<!-- /var --></div>
                        <div class="detail">4.5 thinks more often but shallowly</div>
                    </div>
                    <div class="stat-card">
                        <div class="label">Thinking Depth</div>
                        <div class="value v-blue">+<!-- var: (cost.avg_thinking_when_used_b / cost.avg_thinking_when_used_a - 1) * 100 | .0f -->58<!-- /var -->%</div>
                        <div class="detail"><!-- var: cost.avg_thinking_when_used_b -->4,175<!-- /var --> vs <!-- var: cost.avg_thinking_when_used_a -->2,635<!-- /var --> chars when thinking</div>
                    </div>
                </div>

                <p>Thinking fraction is the largest overall effect in the study (d=<!-- var: thinking.effect_d -->0.67<!-- /var -->, medium by Cohen&rsquo;s convention). Opus 4.5 thinks on <!-- var: cost.thinking_ratio_a -->75%<!-- /var --> of tasks but shallowly; Opus 4.6 thinks on <!-- var: cost.thinking_ratio_b -->58%<!-- /var --> of tasks but more deeply when it does (<!-- var: cost.avg_thinking_when_used_b -->4,175<!-- /var --> vs <!-- var: cost.avg_thinking_when_used_a -->2,635<!-- /var --> chars). The pattern suggests 4.6 has better calibration of <em>when</em> thinking is needed, reserving it for moderate-and-above complexity.</p>

                <h3>Calibration by Complexity</h3>

                <div class="legend">
                    <span><span class="dot dot-a"></span> Opus 4.5</span>
                    <span><span class="dot dot-b"></span> Opus 4.6</span>
                </div>

<!-- GENERATED-TABLE: cost-thinking-calibration -->
<table>
    <thead>
        <tr><th>Complexity</th><th>Distribution</th><th class="right">4.5 (n)</th><th class="right">4.6 (n)</th><th class="right">&Delta;</th></tr>
    </thead>
    <tbody>
        <tr>
            <td class="label-cell">Trivial &mdash; thinking %</td>
            <td class="bar-cell"><div class="bar-pair">
                <div class="bar-row"><span class="bar-tag">A</span><div class="bar-track"><div class="bar-fill a" style="width:76.6%"></div><div class="bar-ci" style="left:73.6%;width:5.8%" title="95% CI: [73.6, 79.4]"></div></div><span class="bar-val">76.6%</span></div>
                <div class="bar-row"><span class="bar-tag">B</span><div class="bar-track"><div class="bar-fill b" style="width:42.7%"></div><div class="bar-ci" style="left:36.3%;width:13.2%" title="95% CI: [36.3, 49.4]"></div></div><span class="bar-val">42.7%</span></div>
            </div></td>
            <td class="right mono">808</td>
            <td class="right mono">213</td>
            <td class="right mono v-orange">&minus;34pp</td>
        </tr>
        <tr>
            <td class="label-cell">Simple &mdash; thinking %</td>
            <td class="bar-cell"><div class="bar-pair">
                <div class="bar-row"><span class="bar-tag">A</span><div class="bar-track"><div class="bar-fill a" style="width:91.3%"></div><div class="bar-ci" style="left:87.9%;width:6.0%" title="95% CI: [87.9, 93.8]"></div></div><span class="bar-val">91.3%</span></div>
                <div class="bar-row"><span class="bar-tag">B</span><div class="bar-track"><div class="bar-fill b" style="width:58.9%"></div><div class="bar-ci" style="left:50.3%;width:16.7%" title="95% CI: [50.3, 67.0]"></div></div><span class="bar-val">58.9%</span></div>
            </div></td>
            <td class="right mono">345</td>
            <td class="right mono">129</td>
            <td class="right mono v-orange">&minus;32pp</td>
        </tr>
        <tr>
            <td class="label-cell">Moderate &mdash; thinking %</td>
            <td class="bar-cell"><div class="bar-pair">
                <div class="bar-row"><span class="bar-tag">A</span><div class="bar-track"><div class="bar-fill a" style="width:89.1%"></div><div class="bar-ci" style="left:85.5%;width:6.4%" title="95% CI: [85.5, 91.9]"></div></div><span class="bar-val">89.1%</span></div>
                <div class="bar-row"><span class="bar-tag">B</span><div class="bar-track"><div class="bar-fill b" style="width:90.4%"></div><div class="bar-ci" style="left:84.8%;width:9.3%" title="95% CI: [84.8, 94.1]"></div></div><span class="bar-val">90.4%</span></div>
            </div></td>
            <td class="right mono">367</td>
            <td class="right mono">157</td>
            <td class="right mono ">+1pp</td>
        </tr>
        <tr>
            <td class="label-cell">Complex &mdash; thinking %</td>
            <td class="bar-cell"><div class="bar-pair">
                <div class="bar-row"><span class="bar-tag">A</span><div class="bar-track"><div class="bar-fill a" style="width:75.8%"></div><div class="bar-ci" style="left:69.2%;width:12.1%" title="95% CI: [69.2, 81.3]"></div></div><span class="bar-val">75.8%</span></div>
                <div class="bar-row"><span class="bar-tag">B</span><div class="bar-track"><div class="bar-fill b" style="width:93.2%"></div><div class="bar-ci" style="left:85.1%;width:11.9%" title="95% CI: [85.1, 97.1]"></div></div><span class="bar-val">93.2%</span></div>
            </div></td>
            <td class="right mono">190</td>
            <td class="right mono">74</td>
            <td class="right mono v-blue">+17pp</td>
        </tr>
        <tr>
            <td class="label-cell">Major &mdash; thinking %</td>
            <td class="bar-cell"><div class="bar-pair">
                <div class="bar-row"><span class="bar-tag">A</span><div class="bar-track"><div class="bar-fill a" style="width:73.7%"></div><div class="bar-ci" style="left:51.2%;width:37.0%" title="95% CI: [51.2, 88.2]"></div></div><span class="bar-val">73.7%</span></div>
                <div class="bar-row"><span class="bar-tag">B</span><div class="bar-track"><div class="bar-fill b" style="width:77.8%"></div><div class="bar-ci" style="left:54.8%;width:36.2%" title="95% CI: [54.8, 91.0]"></div></div><span class="bar-val">77.8%</span></div>
            </div></td>
            <td class="right mono">19</td>
            <td class="right mono">18</td>
            <td class="right mono ">+4pp</td>
        </tr>
    </tbody>
</table>
<!-- /GENERATED-TABLE: cost-thinking-calibration -->

                <div class="callout blue">
                    <strong>Thinking calibration:</strong> Opus 4.6 shows better calibration of when thinking is needed. It skips thinking for <!-- var: tokens.thinking_skip_trivial_b * 100 | .0f -->57<!-- /var -->% of trivial tasks (vs <!-- var: tokens.thinking_skip_trivial_a * 100 | .0f -->23<!-- /var -->% for Opus 4.5), but engages thinking for 90%+ of moderate and complex tasks. Opus 4.5 over-thinks easy problems; at moderate complexity, both converge.
                </div>

                <!-- expand: thinking-calibration-details -->

                <h3>Thinking Depth by Task Type</h3>

<!-- GENERATED-TABLE: thinking-depth-by-type -->
<table>
    <thead>
        <tr><th>Task Type</th><th>Thinking Depth</th><th class="right">4.5 chars</th><th class="right">4.6 chars</th><th class="right">Ratio</th></tr>
    </thead>
    <tbody>
        <tr><td class="label-cell">Greenfield</td>
            <td class="bar-cell"><div class="bar-pair">
                <div class="bar-row"><span class="bar-tag">A</span><div class="bar-track"><div class="bar-fill a" style="width:40.7%"></div></div><span class="bar-val">3,068</span></div>
                <div class="bar-row"><span class="bar-tag">B</span><div class="bar-track"><div class="bar-fill b" style="width:100.0%"></div></div><span class="bar-val">7,536</span></div>
            </div></td>
            <td class="right mono">3,068</td><td class="right mono">7,536</td><td class="right mono v-blue">2.5&times;</td></tr>
        <tr><td class="label-cell">Refactor</td>
            <td class="bar-cell"><div class="bar-pair">
                <div class="bar-row"><span class="bar-tag">A</span><div class="bar-track"><div class="bar-fill a" style="width:45.0%"></div></div><span class="bar-val">3,390</span></div>
                <div class="bar-row"><span class="bar-tag">B</span><div class="bar-track"><div class="bar-fill b" style="width:74.6%"></div></div><span class="bar-val">5,620</span></div>
            </div></td>
            <td class="right mono">3,390</td><td class="right mono">5,620</td><td class="right mono v-blue">1.7&times;</td></tr>
        <tr><td class="label-cell">Bugfix</td>
            <td class="bar-cell"><div class="bar-pair">
                <div class="bar-row"><span class="bar-tag">A</span><div class="bar-track"><div class="bar-fill a" style="width:37.5%"></div></div><span class="bar-val">2,829</span></div>
                <div class="bar-row"><span class="bar-tag">B</span><div class="bar-track"><div class="bar-fill b" style="width:90.3%"></div></div><span class="bar-val">6,805</span></div>
            </div></td>
            <td class="right mono">2,829</td><td class="right mono">6,805</td><td class="right mono v-blue">2.4&times;</td></tr>
        <tr><td class="label-cell">Feature</td>
            <td class="bar-cell"><div class="bar-pair">
                <div class="bar-row"><span class="bar-tag">A</span><div class="bar-track"><div class="bar-fill a" style="width:37.7%"></div></div><span class="bar-val">2,840</span></div>
                <div class="bar-row"><span class="bar-tag">B</span><div class="bar-track"><div class="bar-fill b" style="width:67.6%"></div></div><span class="bar-val">5,093</span></div>
            </div></td>
            <td class="right mono">2,840</td><td class="right mono">5,093</td><td class="right mono v-blue">1.8&times;</td></tr>
        <tr><td class="label-cell">Investigation</td>
            <td class="bar-cell"><div class="bar-pair">
                <div class="bar-row"><span class="bar-tag">A</span><div class="bar-track"><div class="bar-fill a" style="width:36.4%"></div></div><span class="bar-val">2,741</span></div>
                <div class="bar-row"><span class="bar-tag">B</span><div class="bar-track"><div class="bar-fill b" style="width:32.1%"></div></div><span class="bar-val">2,416</span></div>
            </div></td>
            <td class="right mono">2,741</td><td class="right mono">2,416</td><td class="right mono">0.9&times;</td></tr>
        <tr><td class="label-cell">Sysadmin</td>
            <td class="bar-cell"><div class="bar-pair">
                <div class="bar-row"><span class="bar-tag">A</span><div class="bar-track"><div class="bar-fill a" style="width:20.8%"></div></div><span class="bar-val">1,567</span></div>
                <div class="bar-row"><span class="bar-tag">B</span><div class="bar-track"><div class="bar-fill b" style="width:27.4%"></div></div><span class="bar-val">2,065</span></div>
            </div></td>
            <td class="right mono">1,567</td><td class="right mono">2,065</td><td class="right mono">1.3&times;</td></tr>
        <tr><td class="label-cell">Continuation</td>
            <td class="bar-cell"><div class="bar-pair">
                <div class="bar-row"><span class="bar-tag">A</span><div class="bar-track"><div class="bar-fill a" style="width:23.4%"></div></div><span class="bar-val">1,763</span></div>
                <div class="bar-row"><span class="bar-tag">B</span><div class="bar-track"><div class="bar-fill b" style="width:32.0%"></div></div><span class="bar-val">2,411</span></div>
            </div></td>
            <td class="right mono">1,763</td><td class="right mono">2,411</td><td class="right mono">1.4&times;</td></tr>
        <tr><td class="label-cell">Docs</td>
            <td class="bar-cell"><div class="bar-pair">
                <div class="bar-row"><span class="bar-tag">A</span><div class="bar-track"><div class="bar-fill a" style="width:22.2%"></div></div><span class="bar-val">1,674</span></div>
                <div class="bar-row"><span class="bar-tag">B</span><div class="bar-track"><div class="bar-fill b" style="width:85.7%"></div></div><span class="bar-val">6,459</span></div>
            </div></td>
            <td class="right mono">1,674</td><td class="right mono">6,459</td><td class="right mono v-blue">3.9&times;</td></tr>
        <tr><td class="label-cell">Port</td>
            <td class="bar-cell"><div class="bar-pair">
                <div class="bar-row"><span class="bar-tag">A</span><div class="bar-track"><div class="bar-fill a" style="width:43.9%"></div></div><span class="bar-val">3,307</span></div>
                <div class="bar-row"><span class="bar-tag">B</span><div class="bar-track"><div class="bar-fill b" style="width:92.5%"></div></div><span class="bar-val">6,974</span></div>
            </div></td>
            <td class="right mono">3,307</td><td class="right mono">6,974</td><td class="right mono v-blue">2.1&times;</td></tr>
    </tbody>
</table>
<!-- /GENERATED-TABLE: thinking-depth-by-type -->

                <h3>Cross-Cut Detail</h3>
                <!-- expand: findings-thinking -->

                <div class="stat-note">
                    <strong>Significance:</strong> Thinking fraction survives Bonferroni correction across trivial, simple, and moderate complexity strata, and most cross-cut slices. The complex stratum is non-significant (p=0.75), likely due to smaller sample size. This is the most robust and widespread finding in the study.
                </div>

                <p>Thinking calibration is one manifestation of broader behavioral differences between the models. The next section examines other behavioral patterns&mdash;subagent deployment, planning adoption, and effort distribution.</p>
            </section>

            <!-- ===== 4. BEHAVIORAL PATTERNS ===== -->
            <section id="behavior">
                <h2>4. Behavioral Patterns</h2>

                <div class="stat-row">
                    <div class="stat-card">
                        <div class="label">Planning Adoption</div>
                        <div class="value v-blue"><!-- var: round(planning.rate_b / planning.rate_a) | .0f -->8<!-- /var -->&times;</div>
                        <div class="detail"><!-- var: planning.rate_b -->13.9<!-- /var -->% vs <!-- var: planning.rate_a -->1.7<!-- /var -->% of tasks</div>
                    </div>
                    <div class="stat-card">
                        <div class="label">Explore Subagents</div>
                        <div class="value v-dark"><!-- var: behavior.explore_count_b / behavior.total_subagents_b * 100 | .0f -->74<!-- /var -->% vs <!-- var: behavior.explore_count_a / behavior.total_subagents_a * 100 | .0f -->47<!-- /var -->%</div>
                        <div class="detail">4.6 favors read-only exploration</div>
                    </div>
                    <div class="stat-card">
                        <div class="label">Autonomous Subagents</div>
                        <div class="value v-dark"><!-- var: behavior.subagent_autonomous_b / behavior.total_subagents_b * 100 | .0f -->84<!-- /var -->% vs <!-- var: behavior.subagent_autonomous_a / behavior.total_subagents_a * 100 | .0f -->54<!-- /var -->%</div>
                        <div class="detail">4.6 self-initiates most subagent calls</div>
                    </div>
                </div>

                <p>Beyond token economics, the models differ in <em>how</em> they approach tasks. Opus 4.6 plans more often (<!-- var: planning.rate_b -->13.9<!-- /var -->% vs <!-- var: planning.rate_a -->1.7<!-- /var -->% of tasks), deploys more subagents, and favors read-only exploration over general-purpose workers. These behavioral differences are among the most visible in the dataset, though the Claude Code platform itself evolved between the two collection periods&mdash;some of the shift may reflect SDK changes rather than model decisions.</p>

                <div class="legend">
                    <span><span class="dot dot-a"></span> Opus 4.5</span>
                    <span><span class="dot dot-b"></span> Opus 4.6</span>
                </div>

                <h3>Subagent &amp; Planning Adoption</h3>
<!-- GENERATED-TABLE: behavior-adoption -->
<table>
    <thead>
        <tr><th>Metric</th><th>Distribution</th><th class="right">4.5</th><th class="right">4.6</th><th class="right">&Delta;</th></tr>
    </thead>
    <tbody>
        <tr>
            <td class="label-cell">Tasks using planning mode</td>
            <td class="bar-cell"><div class="bar-pair">
                <div class="bar-row"><span class="bar-tag">A</span><div class="bar-track"><div class="bar-fill a" style="width:1.7%"></div><div class="bar-ci" style="left:1.2%;width:1.2%" title="95% CI: [1.2, 2.4]"></div></div><span class="bar-val">1.7%</span></div>
                <div class="bar-row"><span class="bar-tag">B</span><div class="bar-track"><div class="bar-fill b" style="width:13.9%"></div><div class="bar-ci" style="left:11.3%;width:5.6%" title="95% CI: [11.3, 16.9]"></div></div><span class="bar-val">13.9%</span></div>
            </div></td>
            <td class="right mono">29</td>
            <td class="right mono">82</td>
            <td class="right mono" style="color:var(--blue)">B +12.2pp</td>
        </tr>
        <tr>
            <td class="label-cell">Tasks using subagents</td>
            <td class="bar-cell"><div class="bar-pair">
                <div class="bar-row"><span class="bar-tag">A</span><div class="bar-track"><div class="bar-fill a" style="width:7.3%"></div><div class="bar-ci" style="left:6.2%;width:2.5%" title="95% CI: [6.2, 8.7]"></div></div><span class="bar-val">7.3%</span></div>
                <div class="bar-row"><span class="bar-tag">B</span><div class="bar-track"><div class="bar-fill b" style="width:21.3%"></div><div class="bar-ci" style="left:18.2%;width:6.6%" title="95% CI: [18.2, 24.8]"></div></div><span class="bar-val">21.3%</span></div>
            </div></td>
            <td class="right mono">127</td>
            <td class="right mono">126</td>
            <td class="right mono" style="color:var(--blue)">B +14.0pp</td>
        </tr>
        <tr>
            <td class="label-cell">Autonomous subagent calls</td>
            <td class="bar-cell"><div class="bar-pair">
                <div class="bar-row"><span class="bar-tag">A</span><div class="bar-track"><div class="bar-fill a" style="width:54.4%"></div><div class="bar-ci" style="left:48.6%;width:11.5%" title="95% CI: [48.6, 60.1]"></div></div><span class="bar-val">54.4%</span></div>
                <div class="bar-row"><span class="bar-tag">B</span><div class="bar-track"><div class="bar-fill b" style="width:84.0%"></div><div class="bar-ci" style="left:79.0%;width:8.9%" title="95% CI: [79.0, 87.9]"></div></div><span class="bar-val">84.0%</span></div>
            </div></td>
            <td class="right mono">154</td>
            <td class="right mono">220</td>
            <td class="right mono" style="color:var(--blue)">B +29.6pp</td>
        </tr>
    </tbody>
</table>
<!-- /GENERATED-TABLE: behavior-adoption -->

                <h3>Subagent Type Distribution</h3>
                <div class="legend">
                    <span><span class="dot dot-a"></span> Opus 4.5</span>
                    <span><span class="dot dot-b"></span> Opus 4.6</span>
                </div>

<!-- GENERATED-TABLE: behavior-subagent-types -->
<table>
    <thead>
        <tr><th>Type</th><th>Distribution</th><th class="right">4.5</th><th class="right">4.6</th><th class="right">&Delta;</th></tr>
    </thead>
    <tbody>
        <tr>
            <td class="label-cell">Explore</td>
            <td class="bar-cell"><div class="bar-pair">
                <div class="bar-row"><span class="bar-tag">A</span><div class="bar-track"><div class="bar-fill a" style="width:47.0%"></div><div class="bar-ci" style="left:41.3%;width:11.6%" title="95% CI: [41.3, 52.8]"></div></div><span class="bar-val">47.0%</span></div>
                <div class="bar-row"><span class="bar-tag">B</span><div class="bar-track"><div class="bar-fill b" style="width:74.0%"></div><div class="bar-ci" style="left:68.4%;width:10.6%" title="95% CI: [68.4, 79.0]"></div></div><span class="bar-val">74.0%</span></div>
            </div></td>
            <td class="right mono">133</td>
            <td class="right mono">194</td>
            <td class="right mono" style="color:var(--blue)">B +27.0pp</td>
        </tr>
        <tr>
            <td class="label-cell">General-purpose</td>
            <td class="bar-cell"><div class="bar-pair">
                <div class="bar-row"><span class="bar-tag">A</span><div class="bar-track"><div class="bar-fill a" style="width:36.7%"></div><div class="bar-ci" style="left:31.3%;width:11.2%" title="95% CI: [31.3, 42.5]"></div></div><span class="bar-val">36.7%</span></div>
                <div class="bar-row"><span class="bar-tag">B</span><div class="bar-track"><div class="bar-fill b" style="width:15.3%"></div><div class="bar-ci" style="left:11.4%;width:8.7%" title="95% CI: [11.4, 20.1]"></div></div><span class="bar-val">15.3%</span></div>
            </div></td>
            <td class="right mono">104</td>
            <td class="right mono">40</td>
            <td class="right mono" style="color:var(--orange)">A +21.5pp</td>
        </tr>
        <tr>
            <td class="label-cell">Plan</td>
            <td class="bar-cell"><div class="bar-pair">
                <div class="bar-row"><span class="bar-tag">A</span><div class="bar-track"><div class="bar-fill a" style="width:5.3%"></div><div class="bar-ci" style="left:3.2%;width:5.3%" title="95% CI: [3.2, 8.6]"></div></div><span class="bar-val">5.3%</span></div>
                <div class="bar-row"><span class="bar-tag">B</span><div class="bar-track"><div class="bar-fill b" style="width:6.9%"></div><div class="bar-ci" style="left:4.4%;width:6.2%" title="95% CI: [4.4, 10.6]"></div></div><span class="bar-val">6.9%</span></div>
            </div></td>
            <td class="right mono">15</td>
            <td class="right mono">18</td>
            <td class="right mono" style="color:var(--mid-gray)">&asymp; Tie</td>
        </tr>
        <tr>
            <td class="label-cell">Bash</td>
            <td class="bar-cell"><div class="bar-pair">
                <div class="bar-row"><span class="bar-tag">A</span><div class="bar-track"><div class="bar-fill a" style="width:2.1%"></div><div class="bar-ci" style="left:1.0%;width:3.6%" title="95% CI: [1.0, 4.5]"></div></div><span class="bar-val">2.1%</span></div>
                <div class="bar-row"><span class="bar-tag">B</span><div class="bar-track"><div class="bar-fill b" style="width:3.4%"></div><div class="bar-ci" style="left:1.8%;width:4.6%" title="95% CI: [1.8, 6.4]"></div></div><span class="bar-val">3.4%</span></div>
            </div></td>
            <td class="right mono">6</td>
            <td class="right mono">9</td>
            <td class="right mono" style="color:var(--mid-gray)">&asymp; Tie</td>
        </tr>
    </tbody>
</table>
<!-- /GENERATED-TABLE: behavior-subagent-types -->

                <div class="callout blue">
                    <strong>Subagent strategies diverge:</strong> Both models deploy similar total subagents (<!-- var: behavior.total_subagents_a | .0f -->283<!-- /var --> vs <!-- var: behavior.total_subagents_b | .0f -->262<!-- /var -->) but they serve different purposes. For Opus 4.6, <!-- var: behavior.explore_count_b / behavior.total_subagents_b * 100 | .0f -->74<!-- /var -->% are lightweight, read-only Explore agents that gather context before implementation begins, with <!-- var: behavior.gp_count_b / behavior.total_subagents_b * 100 | .0f -->15<!-- /var -->% general-purpose. Opus 4.5 splits its subagents more evenly&mdash;<!-- var: behavior.explore_count_a / behavior.total_subagents_a * 100 | .0f -->47<!-- /var -->% Explore, <!-- var: behavior.gp_count_a / behavior.total_subagents_a * 100 | .0f -->37<!-- /var -->% general-purpose implementation workers that visibly modify files. Both front-load research, but Opus 4.6 concentrates even more heavily on read-only exploration.
                </div>

                <div class="stat-note">
                    <strong>Significance:</strong> Autonomy level distribution (p&lt;<!-- var: 0.05 / findings.total_tests | .7f -->0.0000945<!-- /var -->, Cram&eacute;r&rsquo;s V=<!-- var: stat.autonomy_v -->0.15<!-- /var -->) survives Bonferroni correction.
                </div>

                <h3>Planning Adoption</h3>

                <p>Opus 4.6 enters plan mode on <!-- var: planning.rate_b -->13.9<!-- /var -->% of tasks (<!-- var: planning.total_planned_b -->82<!-- /var --> of <!-- var: planning.total_tasks_b -->591<!-- /var -->) vs <!-- var: planning.rate_a -->1.7<!-- /var -->% for Opus 4.5. Adoption scales steeply with complexity: <!-- var: planning.complex_rate_b -->51.4<!-- /var -->% at complex, <!-- var: planning.major_rate_b -->72.2<!-- /var -->% at major. Planned tasks show a modest alignment benefit (+<!-- var: planning.alignment_delta_b -->0.20<!-- /var --> overall) that diminishes at complex and major tiers.</p>

<!-- GENERATED-TABLE: planning-adoption -->
<table>
    <thead>
        <tr><th>Metric</th><th>Distribution</th><th class="right">4.5</th><th class="right">4.6</th></tr>
    </thead>
    <tbody>
        <tr>
            <td class="label-cell">Planning adoption rate</td>
            <td class="bar-cell"><div class="bar-pair">
                <div class="bar-row"><span class="bar-tag">A</span><div class="bar-track"><div class="bar-fill a" style="width:1.7%"></div></div><span class="bar-val">1.7%</span></div>
                <div class="bar-row"><span class="bar-tag">B</span><div class="bar-track"><div class="bar-fill b" style="width:13.9%"></div></div><span class="bar-val">13.9%</span></div>
            </div></td>
            <td class="right mono">29 tasks</td>
            <td class="right mono">82 tasks</td>
        </tr>
    </tbody>
</table>
<!-- /GENERATED-TABLE: planning-adoption -->

<!-- GENERATED-TABLE: planning-by-complexity -->
<table>
    <thead>
        <tr><th>Complexity</th><th>Distribution</th><th class="right">4.5</th><th class="right">4.6</th></tr>
    </thead>
    <tbody>
        <tr>
            <td class="label-cell">Trivial</td>
            <td class="bar-cell"><div class="bar-pair">
                <div class="bar-row"><span class="bar-tag">A</span><div class="bar-track"><div class="bar-fill a" style="width:0.0%"></div></div><span class="bar-val">0.0%</span></div>
                <div class="bar-row"><span class="bar-tag">B</span><div class="bar-track"><div class="bar-fill b" style="width:0.0%"></div></div><span class="bar-val">0.0%</span></div>
            </div></td>
            <td class="right mono">0/808</td>
            <td class="right mono">0/213</td>
        </tr>
        <tr>
            <td class="label-cell">Simple</td>
            <td class="bar-cell"><div class="bar-pair">
                <div class="bar-row"><span class="bar-tag">A</span><div class="bar-track"><div class="bar-fill a" style="width:0.3%"></div></div><span class="bar-val">0.3%</span></div>
                <div class="bar-row"><span class="bar-tag">B</span><div class="bar-track"><div class="bar-fill b" style="width:3.1%"></div></div><span class="bar-val">3.1%</span></div>
            </div></td>
            <td class="right mono">1/345</td>
            <td class="right mono">4/129</td>
        </tr>
        <tr>
            <td class="label-cell">Moderate</td>
            <td class="bar-cell"><div class="bar-pair">
                <div class="bar-row"><span class="bar-tag">A</span><div class="bar-track"><div class="bar-fill a" style="width:2.2%"></div></div><span class="bar-val">2.2%</span></div>
                <div class="bar-row"><span class="bar-tag">B</span><div class="bar-track"><div class="bar-fill b" style="width:17.2%"></div></div><span class="bar-val">17.2%</span></div>
            </div></td>
            <td class="right mono">8/367</td>
            <td class="right mono">27/157</td>
        </tr>
        <tr>
            <td class="label-cell">Complex</td>
            <td class="bar-cell"><div class="bar-pair">
                <div class="bar-row"><span class="bar-tag">A</span><div class="bar-track"><div class="bar-fill a" style="width:7.4%"></div></div><span class="bar-val">7.4%</span></div>
                <div class="bar-row"><span class="bar-tag">B</span><div class="bar-track"><div class="bar-fill b" style="width:51.4%"></div></div><span class="bar-val">51.4%</span></div>
            </div></td>
            <td class="right mono">14/190</td>
            <td class="right mono">38/74</td>
        </tr>
        <tr>
            <td class="label-cell">Major</td>
            <td class="bar-cell"><div class="bar-pair">
                <div class="bar-row"><span class="bar-tag">A</span><div class="bar-track"><div class="bar-fill a" style="width:31.6%"></div></div><span class="bar-val">31.6%</span></div>
                <div class="bar-row"><span class="bar-tag">B</span><div class="bar-track"><div class="bar-fill b" style="width:72.2%"></div></div><span class="bar-val">72.2%</span></div>
            </div></td>
            <td class="right mono">6/19</td>
            <td class="right mono">13/18</td>
        </tr>
    </tbody>
</table>
<!-- /GENERATED-TABLE: planning-by-complexity -->

                <!-- expand: planning-complexity-detail -->
                <!-- expand: planning-by-complexity -->

                <h3>Effort Distribution</h3>

                <p>Effort distribution shows Opus 4.6 allocates more tool calls to research (<!-- var: sessions.research_ratio_b * 100 | .1f -->35.1<!-- /var -->% vs <!-- var: sessions.research_ratio_a * 100 | .1f -->28.3<!-- /var -->%) and fewer to implementation (<!-- var: sessions.impl_ratio_b * 100 | .1f -->17.5<!-- /var -->% vs <!-- var: sessions.impl_ratio_a * 100 | .1f -->27.0<!-- /var -->%), consistent with the research-first approach visible in subagent type preferences.</p>

<!-- GENERATED-TABLE: session-effort -->
<table>
    <thead>
        <tr><th>Metric</th><th>Distribution</th><th class="right">4.5</th><th class="right">4.6</th></tr>
    </thead>
    <tbody>
        <tr>
            <td class="label-cell">Research ratio</td>
            <td class="bar-cell"><div class="bar-pair">
                <div class="bar-row"><span class="bar-tag">A</span><div class="bar-track"><div class="bar-fill a" style="width:28.3%"></div></div><span class="bar-val">28.3%</span></div>
                <div class="bar-row"><span class="bar-tag">B</span><div class="bar-track"><div class="bar-fill b" style="width:35.1%"></div></div><span class="bar-val">35.1%</span></div>
            </div></td>
            <td class="right mono">0.283</td>
            <td class="right mono">0.351</td>
        </tr>
        <tr>
            <td class="label-cell">Implementation ratio</td>
            <td class="bar-cell"><div class="bar-pair">
                <div class="bar-row"><span class="bar-tag">A</span><div class="bar-track"><div class="bar-fill a" style="width:27.0%"></div></div><span class="bar-val">27.0%</span></div>
                <div class="bar-row"><span class="bar-tag">B</span><div class="bar-track"><div class="bar-fill b" style="width:17.5%"></div></div><span class="bar-val">17.5%</span></div>
            </div></td>
            <td class="right mono">0.270</td>
            <td class="right mono">0.175</td>
        </tr>
        <tr>
            <td class="label-cell">Front-load positive %</td>
            <td class="bar-cell"><div class="bar-pair">
                <div class="bar-row"><span class="bar-tag">A</span><div class="bar-track"><div class="bar-fill a" style="width:54.3%"></div></div><span class="bar-val">54.3%</span></div>
                <div class="bar-row"><span class="bar-tag">B</span><div class="bar-track"><div class="bar-fill b" style="width:59.3%"></div></div><span class="bar-val">59.3%</span></div>
            </div></td>
            <td class="right mono">868 tasks</td>
            <td class="right mono">194 tasks</td>
        </tr>
    </tbody>
</table>
<!-- /GENERATED-TABLE: session-effort -->

                <h3>Cross-Cut Detail</h3>
                <!-- expand: findings-behavior -->

                <p>Different behavioral strategies raise the question of whether they lead to different outcomes. The next section examines completion rates, failure rates, and user satisfaction&mdash;the quality signals that the behavioral patterns should ultimately serve.</p>
            </section>

            <!-- ===== 5. QUALITY & SATISFACTION ===== -->
            <section id="quality">
                <h2>5. Quality &amp; Satisfaction</h2>

                <div class="stat-row">
                    <div class="stat-card">
                        <div class="label">Failed Rate</div>
                        <div class="value v-green"><!-- var: stat.failed_rate_b * 100 | .1f -->8.6<!-- /var -->% vs <!-- var: stat.failed_rate_a * 100 | .1f -->13.2<!-- /var -->%</div>
                        <div class="detail">4.6 fails less often (p=<!-- var: quality.failed_p -->0.003<!-- /var -->)</div>
                    </div>
                    <div class="stat-card">
                        <div class="label">Alignment Score</div>
                        <div class="value v-blue">d=<!-- var: quality.alignment_d -->-0.21<!-- /var --></div>
                        <div class="detail">4.6 higher (p=<!-- var: quality.alignment_p -->0.000023<!-- /var -->, Bonferroni)</div>
                    </div>
                    <div class="stat-card">
                        <div class="label">Completion Dist.</div>
                        <div class="value v-blue">p=<!-- var: stat.completion_chi_p -->0.000017<!-- /var --></div>
                        <div class="detail">Chi-square Bonferroni survivor (V=0.10)</div>
                    </div>
                </div>

                <p>LLM-annotated alignment scores (1&ndash;5 scale) show Opus 4.6 scoring higher on average, an effect that survives Bonferroni correction (p=<!-- var: quality.alignment_p -->0.000023<!-- /var -->, d=<!-- var: quality.alignment_d -->-0.21<!-- /var -->). The failed rate difference is also notable: <!-- var: stat.failed_rate_b * 100 | .1f -->8.6<!-- /var -->% of 4.6 tasks fail vs <!-- var: stat.failed_rate_a * 100 | .1f -->13.2<!-- /var -->% for 4.5 (p=<!-- var: quality.failed_p -->0.003<!-- /var -->, significant at FDR but not Bonferroni). Both alignment and failure rate are LLM-classified&mdash;a Claude Haiku model reads each session transcript and assigns scores. The &ldquo;LLM quality judgement&rdquo; approach was abandoned as unreliable (see <a href="#methodology">&sect;10</a>), but alignment scoring proved more robust because it rates user-goal correspondence from observable signals rather than attempting to judge code quality directly.</p>

                <p>Two categorical distributions&mdash;task completion and communication quality&mdash;also survive Bonferroni as chi-square tests, indicating the models differ in <em>how</em> they reach outcomes, not just in outcome rates. Note that the completion <em>distribution</em> test (p=<!-- var: stat.completion_chi_p -->0.000017<!-- /var -->) survives, while the individual completion <em>rate</em> proportion test (p=<!-- var: quality.complete_p -->0.025<!-- /var -->) is marginal. All chi-square tests carry a low-expected-cell-count warning due to rare categories in the 20-status taxonomy.</p>

                <h3>Completion Distribution</h3>
<!-- GENERATED-TABLE: quality-completion -->
<table>
    <thead>
        <tr><th>Outcome</th><th>Distribution (with 95% CI)</th><th class="right">&Delta;</th></tr>
    </thead>
    <tbody>
        <tr>
            <td class="label-cell">Complete</td>
            <td class="bar-cell"><div class="bar-pair">
                <div class="bar-row"><span class="bar-tag">A</span><div class="bar-track"><div class="bar-fill a" style="width:34.8%"></div><div class="bar-ci" style="left:32.6%;width:4.5%" title="95% CI: [32.6, 37.1]"></div></div><span class="bar-val">34.8%</span></div>
                <div class="bar-row"><span class="bar-tag">B</span><div class="bar-track"><div class="bar-fill b" style="width:39.9%"></div><div class="bar-ci" style="left:36.1%;width:7.9%" title="95% CI: [36.1, 43.9]"></div></div><span class="bar-val">39.9%</span></div>
            </div></td>
            <td class="right mono" style="color:var(--blue)">B +5.1pp</td>
        </tr>
        <tr>
            <td class="label-cell">Partial</td>
            <td class="bar-cell"><div class="bar-pair">
                <div class="bar-row"><span class="bar-tag">A</span><div class="bar-track"><div class="bar-fill a" style="width:42.2%"></div><div class="bar-ci" style="left:39.9%;width:4.7%" title="95% CI: [39.9, 44.6]"></div></div><span class="bar-val">42.2%</span></div>
                <div class="bar-row"><span class="bar-tag">B</span><div class="bar-track"><div class="bar-fill b" style="width:46.5%"></div><div class="bar-ci" style="left:42.5%;width:8.0%" title="95% CI: [42.5, 50.6]"></div></div><span class="bar-val">46.5%</span></div>
            </div></td>
            <td class="right mono" style="color:var(--blue)">B +4.3pp</td>
        </tr>
        <tr>
            <td class="label-cell">Interrupted</td>
            <td class="bar-cell"><div class="bar-pair">
                <div class="bar-row"><span class="bar-tag">A</span><div class="bar-track"><div class="bar-fill a" style="width:9.7%"></div><div class="bar-ci" style="left:8.4%;width:2.8%" title="95% CI: [8.4, 11.2]"></div></div><span class="bar-val">9.7%</span></div>
                <div class="bar-row"><span class="bar-tag">B</span><div class="bar-track"><div class="bar-fill b" style="width:4.9%"></div><div class="bar-ci" style="left:3.4%;width:3.5%" title="95% CI: [3.4, 7.0]"></div></div><span class="bar-val">4.9%</span></div>
            </div></td>
            <td class="right mono" style="color:var(--orange)">A +4.8pp</td>
        </tr>
        <tr>
            <td class="label-cell">Failed</td>
            <td class="bar-cell"><div class="bar-pair">
                <div class="bar-row"><span class="bar-tag">A</span><div class="bar-track"><div class="bar-fill a" style="width:13.2%"></div><div class="bar-ci" style="left:11.7%;width:3.2%" title="95% CI: [11.7, 14.9]"></div></div><span class="bar-val">13.2%</span></div>
                <div class="bar-row"><span class="bar-tag">B</span><div class="bar-track"><div class="bar-fill b" style="width:8.6%"></div><div class="bar-ci" style="left:6.6%;width:4.5%" title="95% CI: [6.6, 11.2]"></div></div><span class="bar-val">8.6%</span></div>
            </div></td>
            <td class="right mono" style="color:var(--blue)">B &minus;4.6pp</td>
        </tr>
    </tbody>
</table>
<!-- /GENERATED-TABLE: quality-completion -->

                <h3>Sentiment Distribution</h3>
<!-- GENERATED-TABLE: quality-sentiment -->
<table>
    <thead>
        <tr><th>Sentiment</th><th>Distribution (with 95% CI)</th><th class="right">&Delta;</th></tr>
    </thead>
    <tbody>
        <tr>
            <td class="label-cell">Satisfied</td>
            <td class="bar-cell"><div class="bar-pair">
                <div class="bar-row"><span class="bar-tag">A</span><div class="bar-track"><div class="bar-fill a" style="width:26.0%"></div><div class="bar-ci" style="left:24.0%;width:4.1%" title="95% CI: [24.0, 28.1]"></div></div><span class="bar-val">26.0%</span></div>
                <div class="bar-row"><span class="bar-tag">B</span><div class="bar-track"><div class="bar-fill b" style="width:31.3%"></div><div class="bar-ci" style="left:27.7%;width:7.5%" title="95% CI: [27.7, 35.2]"></div></div><span class="bar-val">31.3%</span></div>
            </div></td>
            <td class="right mono" style="color:var(--blue)">B +5.3pp</td>
        </tr>
        <tr>
            <td class="label-cell">Neutral</td>
            <td class="bar-cell"><div class="bar-pair">
                <div class="bar-row"><span class="bar-tag">A</span><div class="bar-track"><div class="bar-fill a" style="width:56.8%"></div><div class="bar-ci" style="left:54.4%;width:4.7%" title="95% CI: [54.4, 59.1]"></div></div><span class="bar-val">56.8%</span></div>
                <div class="bar-row"><span class="bar-tag">B</span><div class="bar-track"><div class="bar-fill b" style="width:52.6%"></div><div class="bar-ci" style="left:48.6%;width:8.0%" title="95% CI: [48.6, 56.6]"></div></div><span class="bar-val">52.6%</span></div>
            </div></td>
            <td class="right mono" style="color:var(--orange)">A +4.2pp</td>
        </tr>
        <tr>
            <td class="label-cell">Dissatisfied</td>
            <td class="bar-cell"><div class="bar-pair">
                <div class="bar-row"><span class="bar-tag">A</span><div class="bar-track"><div class="bar-fill a" style="width:12.7%"></div><div class="bar-ci" style="left:11.2%;width:3.1%" title="95% CI: [11.2, 14.4]"></div></div><span class="bar-val">12.7%</span></div>
                <div class="bar-row"><span class="bar-tag">B</span><div class="bar-track"><div class="bar-fill b" style="width:12.0%"></div><div class="bar-ci" style="left:9.6%;width:5.2%" title="95% CI: [9.6, 14.9]"></div></div><span class="bar-val">12.0%</span></div>
            </div></td>
            <td class="right mono" style="color:var(--mid-gray)">&asymp; Tie</td>
        </tr>
    </tbody>
</table>
<!-- /GENERATED-TABLE: quality-sentiment -->

                <p>Satisfaction trends higher for 4.6 but does not survive Bonferroni correction. Dissatisfaction rates are essentially tied. Both completion and sentiment are LLM-classified: a Claude Haiku annotator reads the full session transcript for each task, classifying completion status from a 20-category taxonomy and inferring user sentiment from contextual signals (follow-up messages, tone shifts, task abandonment patterns). These classifications were validated through human spot-checks of flagged cases, but no formal inter-rater reliability was computed.</p>

                <div class="callout blue">
                    <strong>Quality confound:</strong> Opus 4.6&rsquo;s different complexity mix (<!-- var: (dataset.complexity_moderate_b + dataset.complexity_complex_b + dataset.complexity_major_b) / dataset.tasks_b * 100 | .0f -->42<!-- /var -->% moderate-and-above vs <!-- var: (dataset.complexity_moderate_a + dataset.complexity_complex_a + dataset.complexity_major_a) / dataset.tasks_a * 100 | .0f -->33<!-- /var -->% for 4.5) means it tackles harder work on average. Despite this, it achieves higher alignment scores and a lower failure rate&mdash;suggesting genuine capability improvement, though task selection remains confounded. The cross-cut detail below shows complexity-stratified alignment scores, consistent with genuine improvement rather than a pure task-mix artifact.
                </div>

                <!-- expand: satisfaction-stat-tests -->

                <h3>Cross-Cut Detail</h3>
                <!-- expand: findings-quality -->

                <p>Quality metrics paint a consistent-but-modest picture: 4.6 fails less and scores higher on alignment, but effect sizes are small (d=0.21) and the LLM-classification methodology adds a layer of uncertainty. The next section asks whether these quality differences manifest in the editing process itself.</p>
            </section>

            <!-- ===== 6. EDIT ACCURACY ===== -->
            <section id="edits">
                <h2>6. Edit Accuracy</h2>

                <div class="stat-row">
                    <div class="stat-card">
                        <div class="label">Rewrite Rate</div>
                        <div class="value v-green"><!-- var: edits.rewrite_rate_b -->10.3%<!-- /var --> vs <!-- var: edits.rewrite_rate_a -->16.6%<!-- /var --></div>
                        <div class="detail">4.6 rewrites less of its own output</div>
                    </div>
                    <div class="stat-card">
                        <div class="label">Editing Tasks</div>
                        <div class="value v-dark"><!-- var: edits.tasks_with_edits_a + edits.tasks_with_edits_b | ,.0f -->946<!-- /var --></div>
                        <div class="detail"><!-- var: edits.tasks_with_edits_a | .0f -->700<!-- /var --> (4.5) + <!-- var: edits.tasks_with_edits_b | .0f -->246<!-- /var --> (4.6)</div>
                    </div>
                    <div class="stat-card">
                        <div class="label">Overlapping Edits</div>
                        <div class="value v-dark"><!-- var: edits.total_overlaps_a -->407<!-- /var --> vs <!-- var: edits.total_overlaps_b -->120<!-- /var --></div>
                        <div class="detail">Self-corrections, error recovery, user-directed, iterative</div>
                    </div>
                </div>

                <p>Edit timeline analysis tracks every Edit and Write tool call, building per-file content ownership maps to detect when a model later overwrites its own earlier output. Opus 4.5 rewrites <!-- var: edits.rewrite_rate_a -->16.6%<!-- /var --> of its edits vs <!-- var: edits.rewrite_rate_b -->10.3%<!-- /var --> for Opus 4.6. Overlap classification reveals the rewrites are predominantly iterative refinement (<!-- var: edits.iterative_a / edits.total_overlaps_a * 100 | .0f -->63<!-- /var -->% for 4.5, largest category), not error recovery.</p>

                <h3>Overlap Breakdown</h3>
<!-- GENERATED-TABLE: edit-overview-inline -->
<table>
    <thead>
        <tr><th>Metric</th><th>Distribution</th><th class="right">4.5</th><th class="right">4.6</th></tr>
    </thead>
    <tbody>
        <tr><td class="label-cell">Tasks with edits</td><td></td><td class="right mono">700</td><td class="right mono">246</td></tr>
        <tr><td class="label-cell">Edit calls (rewrite rate denom.)</td><td></td><td class="right mono">2,453</td><td class="right mono">1,166</td></tr>
        <tr><td class="label-cell">Rewrite rate</td>
            <td class="bar-cell"><div class="bar-pair">
                <div class="bar-row"><span class="bar-tag">A</span><div class="bar-track"><div class="bar-fill a" style="width:16.6%"></div><div class="bar-ci" style="left:15.2%;width:2.9%" title="95% CI: [15.2, 18.1]"></div></div><span class="bar-val">16.6%</span></div>
                <div class="bar-row"><span class="bar-tag">B</span><div class="bar-track"><div class="bar-fill b" style="width:10.3%"></div><div class="bar-ci" style="left:8.7%;width:3.5%" title="95% CI: [8.7, 12.2]"></div></div><span class="bar-val">10.3%</span></div>
            </div></td>
            <td class="right mono">16.6%</td>
            <td class="right mono">10.3%</td></tr>
        <tr><td class="label-cell">Total overlapping edits</td><td></td><td class="right mono">407</td><td class="right mono">120</td></tr>
        <tr><td class="label-cell">Self-corrections</td>
            <td class="bar-cell"><div class="bar-pair">
                <div class="bar-row"><span class="bar-tag">A</span><div class="bar-track"><div class="bar-fill a" style="width:11.5%"></div></div><span class="bar-val">11.5%</span></div>
                <div class="bar-row"><span class="bar-tag">B</span><div class="bar-track"><div class="bar-fill b" style="width:31.7%"></div></div><span class="bar-val">31.7%</span></div>
            </div></td>
            <td class="right mono">47</td><td class="right mono">38</td></tr>
        <tr><td class="label-cell">Error recovery</td>
            <td class="bar-cell"><div class="bar-pair">
                <div class="bar-row"><span class="bar-tag">A</span><div class="bar-track"><div class="bar-fill a" style="width:15.7%"></div></div><span class="bar-val">15.7%</span></div>
                <div class="bar-row"><span class="bar-tag">B</span><div class="bar-track"><div class="bar-fill b" style="width:15.0%"></div></div><span class="bar-val">15.0%</span></div>
            </div></td>
            <td class="right mono">64</td><td class="right mono">18</td></tr>
        <tr><td class="label-cell">User-directed corrections</td>
            <td class="bar-cell"><div class="bar-pair">
                <div class="bar-row"><span class="bar-tag">A</span><div class="bar-track"><div class="bar-fill a" style="width:9.8%"></div></div><span class="bar-val">9.8%</span></div>
                <div class="bar-row"><span class="bar-tag">B</span><div class="bar-track"><div class="bar-fill b" style="width:0.8%"></div></div><span class="bar-val">0.8%</span></div>
            </div></td>
            <td class="right mono">40</td><td class="right mono">1</td></tr>
        <tr><td class="label-cell">Iterative refinement</td>
            <td class="bar-cell"><div class="bar-pair">
                <div class="bar-row"><span class="bar-tag">A</span><div class="bar-track"><div class="bar-fill a" style="width:62.9%"></div></div><span class="bar-val">62.9%</span></div>
                <div class="bar-row"><span class="bar-tag">B</span><div class="bar-track"><div class="bar-fill b" style="width:52.5%"></div></div><span class="bar-val">52.5%</span></div>
            </div></td>
            <td class="right mono">256</td><td class="right mono">63</td></tr>
    </tbody>
</table>
<!-- /GENERATED-TABLE: edit-overview-inline -->

                <p>The overlap composition tells a more nuanced story than the headline rewrite rate. When Opus 4.6 <em>does</em> overlap, a larger share is self-correction (<!-- var: edits.self_correction_b / edits.total_overlaps_b * 100 | .1f -->31.7<!-- /var -->% vs <!-- var: edits.self_correction_a / edits.total_overlaps_a * 100 | .1f -->11.5<!-- /var -->% for 4.5)&mdash;meaning 4.6 catches and fixes its own mistakes more explicitly. Opus 4.5&rsquo;s overlaps are more heavily iterative refinement (<!-- var: edits.iterative_a / edits.total_overlaps_a * 100 | .0f -->63<!-- /var -->% vs <!-- var: edits.iterative_b / edits.total_overlaps_b * 100 | .0f -->52<!-- /var -->%), suggesting gradual adjustment rather than correction. Error recovery rates are comparable (<!-- var: edits.error_recovery_a / edits.total_overlaps_a * 100 | .1f -->15.7<!-- /var -->% vs <!-- var: edits.error_recovery_b / edits.total_overlaps_b * 100 | .1f -->15.0<!-- /var -->%).</p>

                <!-- expand: edit-accuracy-overview -->
                <!-- expand: edit-accuracy-by-complexity -->

                <h3>Cross-Cut Detail</h3>
                <!-- expand: findings-editing -->

                <div class="stat-note">
                    <strong>Interpretation:</strong> A lower rewrite rate is consistent with Opus 4.6&rsquo;s research-first approach&mdash;investigating before editing reduces the need for later corrections. However, the distinction between &ldquo;self-correction&rdquo; and &ldquo;iterative refinement&rdquo; is heuristic-based, and Opus 4.6&rsquo;s overlap sample is small (n=<!-- var: edits.total_overlaps_b -->120<!-- /var -->), making per-category percentages volatile&mdash;the user-directed category at 0.8% represents a single edit.
                </div>

                <p>Edit patterns capture one dimension of how the models work; the next section broadens the lens to overall resource usage and complexity scaling.</p>
            </section>

            <!-- ===== 7. COMPLEXITY &amp; RESOURCE USAGE ===== -->
            <section id="complexity">
                <h2>7. Complexity &amp; Resource Usage</h2>

                <div class="stat-row">
                    <div class="stat-card">
                        <div class="label">Tool Calls / Task</div>
                        <div class="value v-blue"><!-- var: dataset.total_tool_calls_b / dataset.tasks_b | .1f -->16.3<!-- /var --> vs <!-- var: dataset.total_tool_calls_a / dataset.tasks_a | .1f -->10.4<!-- /var --></div>
                        <div class="detail">Strongest behavioral signal (p&lt;0.000001, d=<!-- var: stat.tool_calls_d | .2f -->-0.29<!-- /var -->)</div>
                    </div>
                    <div class="stat-card">
                        <div class="label">Complexity Mix</div>
                        <div class="value v-dark"><!-- var: (dataset.complexity_moderate_b + dataset.complexity_complex_b + dataset.complexity_major_b) / dataset.tasks_b * 100 | .0f -->42<!-- /var -->% vs <!-- var: (dataset.complexity_moderate_a + dataset.complexity_complex_a + dataset.complexity_major_a) / dataset.tasks_a * 100 | .0f -->33<!-- /var -->%</div>
                        <div class="detail">4.6 has more moderate-and-above tasks</div>
                    </div>
                    <div class="stat-card">
                        <div class="label">Lines Added</div>
                        <div class="value v-dark"><!-- var: dataset.total_lines_added_b / dataset.tasks_b | .0f -->109<!-- /var --> vs <!-- var: dataset.total_lines_added_a / dataset.tasks_a | .0f -->103<!-- /var --></div>
                        <div class="detail">Only +<!-- var: (dataset.total_lines_added_b / dataset.tasks_b / (dataset.total_lines_added_a / dataset.tasks_a) - 1) * 100 | .0f -->6<!-- /var -->% despite <!-- var: (dataset.total_tool_calls_b / dataset.tasks_b / (dataset.total_tool_calls_a / dataset.tasks_a) - 1) * 100 | .0f -->57<!-- /var -->% more tool calls</div>
                    </div>
                </div>

                <div class="legend">
                    <span><span class="dot dot-a"></span> Opus 4.5</span>
                    <span><span class="dot dot-b"></span> Opus 4.6</span>
                </div>

                <h3>Task Distribution by Complexity</h3>
<!-- GENERATED-TABLE: complexity-distribution -->
<table>
    <thead>
        <tr><th>Complexity</th><th>Distribution</th><th class="right">4.5 n</th><th class="right">4.6 n</th></tr>
    </thead>
    <tbody>
        <tr>
            <td class="label-cell">Trivial</td>
            <td class="bar-cell"><div class="bar-pair">
                <div class="bar-row"><span class="bar-tag">A</span><div class="bar-track"><div class="bar-fill a" style="width:46.7%"></div><div class="bar-ci" style="left:44.4%;width:4.7%" title="95% CI: [44.4, 49.1]"></div></div><span class="bar-val">46.7%</span></div>
                <div class="bar-row"><span class="bar-tag">B</span><div class="bar-track"><div class="bar-fill b" style="width:36.0%"></div><div class="bar-ci" style="left:32.3%;width:7.7%" title="95% CI: [32.3, 40.0]"></div></div><span class="bar-val">36.0%</span></div>
            </div></td>
            <td class="right mono">808</td>
            <td class="right mono">213</td>
        </tr>
        <tr>
            <td class="label-cell">Simple</td>
            <td class="bar-cell"><div class="bar-pair">
                <div class="bar-row"><span class="bar-tag">A</span><div class="bar-track"><div class="bar-fill a" style="width:20.0%"></div><div class="bar-ci" style="left:18.1%;width:3.8%" title="95% CI: [18.1, 21.9]"></div></div><span class="bar-val">20.0%</span></div>
                <div class="bar-row"><span class="bar-tag">B</span><div class="bar-track"><div class="bar-fill b" style="width:21.8%"></div><div class="bar-ci" style="left:18.7%;width:6.6%" title="95% CI: [18.7, 25.3]"></div></div><span class="bar-val">21.8%</span></div>
            </div></td>
            <td class="right mono">345</td>
            <td class="right mono">129</td>
        </tr>
        <tr>
            <td class="label-cell">Moderate</td>
            <td class="bar-cell"><div class="bar-pair">
                <div class="bar-row"><span class="bar-tag">A</span><div class="bar-track"><div class="bar-fill a" style="width:21.2%"></div><div class="bar-ci" style="left:19.4%;width:3.9%" title="95% CI: [19.4, 23.2]"></div></div><span class="bar-val">21.2%</span></div>
                <div class="bar-row"><span class="bar-tag">B</span><div class="bar-track"><div class="bar-fill b" style="width:26.6%"></div><div class="bar-ci" style="left:23.2%;width:7.1%" title="95% CI: [23.2, 30.3]"></div></div><span class="bar-val">26.6%</span></div>
            </div></td>
            <td class="right mono">367</td>
            <td class="right mono">157</td>
        </tr>
        <tr>
            <td class="label-cell">Complex</td>
            <td class="bar-cell"><div class="bar-pair">
                <div class="bar-row"><span class="bar-tag">A</span><div class="bar-track"><div class="bar-fill a" style="width:11.0%"></div><div class="bar-ci" style="left:9.6%;width:3.0%" title="95% CI: [9.6, 12.6]"></div></div><span class="bar-val">11.0%</span></div>
                <div class="bar-row"><span class="bar-tag">B</span><div class="bar-track"><div class="bar-fill b" style="width:12.5%"></div><div class="bar-ci" style="left:10.1%;width:5.3%" title="95% CI: [10.1, 15.4]"></div></div><span class="bar-val">12.5%</span></div>
            </div></td>
            <td class="right mono">190</td>
            <td class="right mono">74</td>
        </tr>
        <tr>
            <td class="label-cell">Major</td>
            <td class="bar-cell"><div class="bar-pair">
                <div class="bar-row"><span class="bar-tag">A</span><div class="bar-track"><div class="bar-fill a" style="width:1.1%"></div><div class="bar-ci" style="left:0.7%;width:1.0%" title="95% CI: [0.7, 1.7]"></div></div><span class="bar-val">1.1%</span></div>
                <div class="bar-row"><span class="bar-tag">B</span><div class="bar-track"><div class="bar-fill b" style="width:3.0%"></div><div class="bar-ci" style="left:1.9%;width:2.8%" title="95% CI: [1.9, 4.8]"></div></div><span class="bar-val">3.0%</span></div>
            </div></td>
            <td class="right mono">19</td>
            <td class="right mono">18</td>
        </tr>
    </tbody>
</table>
<!-- /GENERATED-TABLE: complexity-distribution -->

                <p>Opus 4.6 sessions skew toward higher complexity: fewer trivial tasks (<!-- var: dataset.complexity_trivial_b / dataset.tasks_b * 100 | .0f -->36<!-- /var -->% vs <!-- var: dataset.complexity_trivial_a / dataset.tasks_a * 100 | .0f -->47<!-- /var -->%) and proportionally more moderate tasks (<!-- var: dataset.complexity_moderate_b / dataset.tasks_b * 100 | .0f -->27<!-- /var -->% vs <!-- var: dataset.complexity_moderate_a / dataset.tasks_a * 100 | .0f -->21<!-- /var -->%). This makes raw aggregate comparisons misleading&mdash;Opus 4.6 is tackling harder work on average.</p>

                <h3>Resource Usage</h3>
<!-- GENERATED-TABLE: complexity-resources -->
<table>
    <thead>
        <tr><th>Metric</th><th>Distribution</th><th class="right">4.5</th><th class="right">4.6</th><th class="right">&Delta;</th></tr>
    </thead>
    <tbody>
        <tr>
            <td class="label-cell">Avg tools per task</td>
            <td class="bar-cell"><div class="bar-pair">
                <div class="bar-row"><span class="bar-tag">A</span><div class="bar-track"><div class="bar-fill a" style="width:63.7%"></div></div><span class="bar-val">10.4</span></div>
                <div class="bar-row"><span class="bar-tag">B</span><div class="bar-track"><div class="bar-fill b" style="width:100.0%"></div></div><span class="bar-val">16.3</span></div>
            </div></td>
            <td class="right mono">10.4</td>
            <td class="right mono">16.3</td>
            <td class="right mono" style="color:var(--blue)">B +57%</td>
        </tr>
        <tr>
            <td class="label-cell">Avg files per task</td>
            <td class="bar-cell"><div class="bar-pair">
                <div class="bar-row"><span class="bar-tag">A</span><div class="bar-track"><div class="bar-fill a" style="width:63.8%"></div></div><span class="bar-val">1.7</span></div>
                <div class="bar-row"><span class="bar-tag">B</span><div class="bar-track"><div class="bar-fill b" style="width:100.0%"></div></div><span class="bar-val">2.6</span></div>
            </div></td>
            <td class="right mono">1.7</td>
            <td class="right mono">2.6</td>
            <td class="right mono" style="color:var(--blue)">B +57%</td>
        </tr>
        <tr>
            <td class="label-cell">Avg lines added</td>
            <td class="bar-cell"><div class="bar-pair">
                <div class="bar-row"><span class="bar-tag">A</span><div class="bar-track"><div class="bar-fill a" style="width:94.5%"></div></div><span class="bar-val">103.4</span></div>
                <div class="bar-row"><span class="bar-tag">B</span><div class="bar-track"><div class="bar-fill b" style="width:100.0%"></div></div><span class="bar-val">109.4</span></div>
            </div></td>
            <td class="right mono">103.4</td>
            <td class="right mono">109.4</td>
            <td class="right mono" style="color:var(--blue)">B +6%</td>
        </tr>
    </tbody>
</table>
<!-- /GENERATED-TABLE: complexity-resources -->


                <div class="callout blue">
                    <strong>The exploration&ndash;output tradeoff:</strong> Tool calls per task is the strongest behavioral signal in the study (p&lt;0.000001, d=0.29, Bonferroni); tools per file also survives correction (p&lt;0.000001, d=0.10). Yet Opus 4.6 produces only 6% more lines of code per task despite <!-- var: (dataset.total_tool_calls_b / dataset.tasks_b / (dataset.total_tool_calls_a / dataset.tasks_a) - 1) * 100 | .0f -->57<!-- /var -->% more tool calls. The extra activity is predominantly read-only research (74% Explore subagents, &sect;4), not proportional output growth. An alternative reading: 4.6 is simply less efficient, doing more work for similar results. The subagent composition data from &sect;4 supports the research interpretation, but the distinction matters.
                </div>

                <div class="stat-note">
                    <strong>Significance:</strong> Tool calls/task (p&lt;0.000001, d=&minus;0.29) and tools/file (p&lt;0.000001, d=&minus;0.10) survive Bonferroni correction. The d=&minus;0.10 for tools/file is negligible in practical terms despite statistical significance, an artifact of large sample size. The tool call averages in the table above (<!-- var: dataset.total_tool_calls_a / dataset.tasks_a | .1f -->10.4<!-- /var --> vs <!-- var: dataset.total_tool_calls_b / dataset.tasks_b | .1f -->16.3<!-- /var -->) include subagent calls; the stat test was run on per-task attributed calls (mean <!-- var: stat.tool_calls_mean_a | .1f -->8.8<!-- /var --> vs <!-- var: stat.tool_calls_mean_b | .1f -->13.4<!-- /var -->), which show the same directional effect.
                </div>

                <!-- expand: complexity-scope -->

                <h3>Cross-Cut Detail</h3>

                <p>Tool calls and tools/file are classified under the &ldquo;behavior&rdquo; theme in the cross-cut analysis. Their per-complexity, per-task-type, and per-iteration breakdowns appear in &sect;4&rsquo;s cross-cut detail (Behavioral Findings). Key results: the tool-call gap is largest for significantly-iterated tasks (d=0.52) and trivial complexity (d=0.31), both Bonferroni-significant.</p>

                <p>The preceding sections examined behavioral, quality, and resource dimensions. The next section examines temporal patterns&mdash;how performance unfolds within and across sessions.</p>
            </section>

            <!-- ===== 8. SESSION DYNAMICS ===== -->
            <section id="sessions">
                <h2>8. Session Dynamics</h2>

                <div class="stat-row">
                    <div class="stat-card">
                        <div class="label">Median Task Duration</div>
                        <div class="value v-dark"><!-- var: dataset.median_duration_b | .0f -->67<!-- /var -->s vs <!-- var: dataset.median_duration_a | .0f -->42<!-- /var -->s</div>
                        <div class="detail">4.6 takes <!-- var: (dataset.median_duration_b - dataset.median_duration_a) / dataset.median_duration_a * 100 | .0f -->58<!-- /var -->% longer per task</div>
                    </div>
                    <div class="stat-card">
                        <div class="label">Explore Phase</div>
                        <div class="value v-blue"><!-- var: sessions.explore_median_b / sessions.explore_median_a | x.1f -->2.2×<!-- /var --></div>
                        <div class="detail"><!-- var: sessions.explore_median_b -->68.7<!-- /var -->s vs <!-- var: sessions.explore_median_a -->31.3<!-- /var -->s median explore duration</div>
                    </div>
                    <div class="stat-card">
                        <div class="label">Active-Time Cost</div>
                        <div class="value v-dark"><!-- var: timing.cost_per_hour_5min_b -->$25.09<!-- /var --> vs <!-- var: timing.cost_per_hour_5min_a -->$20.96<!-- /var -->/hr</div>
                        <div class="detail">5-min idle threshold</div>
                    </div>
                </div>

                <p>Task duration survives Bonferroni correction (p=0.000001), though the effect size is negligible (d=0.005)&mdash;a case of statistical significance without practical significance, driven by sample size. Opus 4.6 takes longer per task (median <!-- var: dataset.median_duration_b | .0f -->67<!-- /var -->s vs <!-- var: dataset.median_duration_a | .0f -->42<!-- /var -->s, a <!-- var: (dataset.median_duration_b - dataset.median_duration_a) / dataset.median_duration_a * 100 | .0f -->58<!-- /var -->% increase). The explore phase runs <!-- var: sessions.explore_median_b / sessions.explore_median_a | x.1f -->2.2×<!-- /var --> longer at median (<!-- var: sessions.explore_median_b -->68.7<!-- /var -->s vs <!-- var: sessions.explore_median_a -->31.3<!-- /var -->s). Effort distribution shows 4.6 allocates more tool calls to research (<!-- var: sessions.research_ratio_b * 100 | .1f -->35.1<!-- /var -->% vs <!-- var: sessions.research_ratio_a * 100 | .1f -->28.3<!-- /var -->%) and fewer to implementation (<!-- var: sessions.impl_ratio_b * 100 | .1f -->17.5<!-- /var -->% vs <!-- var: sessions.impl_ratio_a * 100 | .1f -->27.0<!-- /var -->%). Active-time cost is <!-- var: timing.cost_per_hour_5min_b -->$25.09<!-- /var -->/hour for 4.6 vs <!-- var: timing.cost_per_hour_5min_a -->$20.96<!-- /var -->/hour for 4.5 (5-min idle threshold).</p>

                <h3>Task Duration</h3>

<!-- GENERATED-TABLE: duration-percentiles -->
<table>
    <thead>
        <tr><th>Percentile</th><th>Comparison</th><th class="right">4.5</th><th class="right">4.6</th></tr>
    </thead>
    <tbody>
        <tr><td class="label-cell">p10</td>
            <td class="bar-cell"><div class="bar-pair">
                <div class="bar-row"><span class="bar-tag">A</span><div class="bar-track"><div class="bar-fill a" style="width:1.7%"></div></div><span class="bar-val">8s</span></div>
                <div class="bar-row"><span class="bar-tag">B</span><div class="bar-track"><div class="bar-fill b" style="width:2.1%"></div></div><span class="bar-val">10s</span></div>
            </div></td>
            <td class="right mono">8s</td>
            <td class="right mono">10s</td></tr>
        <tr><td class="label-cell">p25</td>
            <td class="bar-cell"><div class="bar-pair">
                <div class="bar-row"><span class="bar-tag">A</span><div class="bar-track"><div class="bar-fill a" style="width:3.2%"></div></div><span class="bar-val">15s</span></div>
                <div class="bar-row"><span class="bar-tag">B</span><div class="bar-track"><div class="bar-fill b" style="width:4.3%"></div></div><span class="bar-val">21s</span></div>
            </div></td>
            <td class="right mono">15s</td>
            <td class="right mono">21s</td></tr>
        <tr><td class="label-cell">Median</td>
            <td class="bar-cell"><div class="bar-pair">
                <div class="bar-row"><span class="bar-tag">A</span><div class="bar-track"><div class="bar-fill a" style="width:8.9%"></div></div><span class="bar-val">42s</span></div>
                <div class="bar-row"><span class="bar-tag">B</span><div class="bar-track"><div class="bar-fill b" style="width:14.1%"></div></div><span class="bar-val">1.1m</span></div>
            </div></td>
            <td class="right mono">42s</td>
            <td class="right mono">1.1m</td></tr>
        <tr><td class="label-cell">p75</td>
            <td class="bar-cell"><div class="bar-pair">
                <div class="bar-row"><span class="bar-tag">A</span><div class="bar-track"><div class="bar-fill a" style="width:25.0%"></div></div><span class="bar-val">2.0m</span></div>
                <div class="bar-row"><span class="bar-tag">B</span><div class="bar-track"><div class="bar-fill b" style="width:43.4%"></div></div><span class="bar-val">3.5m</span></div>
            </div></td>
            <td class="right mono">2.0m</td>
            <td class="right mono">3.5m</td></tr>
        <tr><td class="label-cell">p90</td>
            <td class="bar-cell"><div class="bar-pair">
                <div class="bar-row"><span class="bar-tag">A</span><div class="bar-track"><div class="bar-fill a" style="width:56.8%"></div></div><span class="bar-val">4.5m</span></div>
                <div class="bar-row"><span class="bar-tag">B</span><div class="bar-track"><div class="bar-fill b" style="width:100.0%"></div></div><span class="bar-val">7.9m</span></div>
            </div></td>
            <td class="right mono">4.5m</td>
            <td class="right mono">7.9m</td></tr>
    </tbody>
</table>
<!-- /GENERATED-TABLE: duration-percentiles -->

                <!-- expand: duration-distribution -->

                <h3>Session Length &amp; Warmup</h3>
                <!-- expand: session-length -->
                <!-- expand: session-warmup -->

                <h3>Active-Time Cost</h3>

<!-- GENERATED-TABLE: idle-sensitivity -->
<table>
    <thead>
        <tr><th>Idle threshold</th><th class="right">4.5 active hrs</th><th class="right">4.6 active hrs</th><th class="right">4.5 $/hr</th><th class="right">4.6 $/hr</th><th class="right">&Delta; $/hr</th></tr>
    </thead>
    <tbody>
        <tr><td class="label-cell">2 min</td>
            <td class="right mono">195.7</td>
            <td class="right mono">62.5</td>
            <td class="right mono">$22.35</td>
            <td class="right mono">$26.57</td>
            <td class="right mono" style="color:var(--orange)">+19%</td></tr>
        <tr><td class="label-cell">5 min</td>
            <td class="right mono">208.6</td>
            <td class="right mono">66.2</td>
            <td class="right mono">$20.96</td>
            <td class="right mono">$25.09</td>
            <td class="right mono" style="color:var(--orange)">+20%</td></tr>
        <tr><td class="label-cell">10 min</td>
            <td class="right mono">224.6</td>
            <td class="right mono">71.6</td>
            <td class="right mono">$19.48</td>
            <td class="right mono">$23.20</td>
            <td class="right mono" style="color:var(--orange)">+19%</td></tr>
        <tr><td class="label-cell">20 min</td>
            <td class="right mono">245.2</td>
            <td class="right mono">77.3</td>
            <td class="right mono">$17.84</td>
            <td class="right mono">$21.50</td>
            <td class="right mono" style="color:var(--orange)">+21%</td></tr>
        <tr><td class="label-cell">30 min</td>
            <td class="right mono">260.3</td>
            <td class="right mono">84.3</td>
            <td class="right mono">$16.81</td>
            <td class="right mono">$19.71</td>
            <td class="right mono" style="color:var(--orange)">+17%</td></tr>
        <tr><td class="label-cell">60 min</td>
            <td class="right mono">295.5</td>
            <td class="right mono">97.3</td>
            <td class="right mono">$14.80</td>
            <td class="right mono">$17.07</td>
            <td class="right mono" style="color:var(--orange)">+15%</td></tr>
    </tbody>
</table>
<!-- /GENERATED-TABLE: idle-sensitivity -->

                <div class="stat-note">
                    <strong>Complication:</strong> Session overlap analysis (<!-- var: timing.overlap_pairs | ,.0f -->1,773<!-- /var --> overlapping pairs, max concurrency <!-- var: timing.max_concurrency | .0f -->11<!-- /var -->) complicates per-session cost attribution. Active-time cost varies with idle threshold (see sensitivity table above), but the directional relationship is stable across all thresholds tested.
                </div>

                <h3>Context Compaction</h3>
                <p>Context-window compaction occurs in <!-- var: compaction.rate_a -->10.1<!-- /var -->% of 4.5 sessions (<!-- var: compaction.sessions_a -->33<!-- /var -->/<!-- var: compaction.total_sessions_a -->327<!-- /var -->) and <!-- var: compaction.rate_b -->12.5<!-- /var -->% of 4.6 sessions (<!-- var: compaction.sessions_b -->17<!-- /var -->/<!-- var: compaction.total_sessions_b -->136<!-- /var -->). Pre/post comparisons show improvement after compaction, but a position-adjusted control group&mdash;splitting non-compacting sessions at the median compaction position to isolate position effects&mdash;reveals the effect is driven by session position, not compaction itself (position-adjusted effect: &minus;<!-- var: -1 * compaction.effect_alignment_a | .2f -->0.23<!-- /var --> for 4.5, &minus;<!-- var: -1 * compaction.effect_alignment_b | .2f -->0.22<!-- /var --> for 4.6). Compaction appears to preserve rather than degrade performance.</p>

                <!-- expand: compaction-overview -->
                <!-- expand: compaction-outcomes -->

                <div class="stat-note">
                    <strong>Position-adjusted effect:</strong> The negative values mean compacting sessions improve less than position-matched controls, suggesting the apparent post-compaction improvement is driven by session position rather than compaction itself. Compaction neither helps nor substantially harms outcomes.
                </div>

                <h3>Cross-Cut Detail</h3>

                <p>Duration is classified under the &ldquo;behavior&rdquo; theme in the cross-cut analysis. Per-task-type and per-iteration breakdowns appear in &sect;4&rsquo;s cross-cut detail (Behavioral Findings). Key results: the duration gap is largest for significantly-iterated tasks (median 99.0s vs 46.7s) and investigation tasks (median 79.9s vs 41.0s), both Bonferroni-significant. Effect sizes are negligible (d&lt;0.1) despite significance&mdash;driven by sample size, not practical magnitude.</p>

                <p>Session dynamics reveal a temporal dimension to the behavioral differences. The next section synthesizes all dimensions into overall model profiles.</p>
            </section>

            <!-- ===== 9. MODEL PROFILES ===== -->
            <section id="profiles">
                <h2>9. Model Profiles</h2>

                <div class="callout">
                    <strong>Not routing recommendations:</strong> These profiles summarize observed behavioral patterns from a single user&rsquo;s workflow. They describe tendencies in this dataset, not inherent model properties. Different users, tasks, or evaluation periods could produce different profiles.
                </div>

                <div class="profile-grid">
                    <div class="profile-card" style="border-left:3px solid var(--orange);">
                        <div class="label" style="color:var(--orange); font-family:'Poppins',sans-serif; font-size:0.65rem; font-weight:600; text-transform:uppercase; letter-spacing:0.08em;">Opus 4.5 &mdash; Observed Pattern</div>
                        <p><strong>Observed approach:</strong> Tends to act first and adjust as needed. Jumps to implementation with minimal upfront research.</p>
                        <p><strong>Thinking:</strong> Thinks on <!-- var: cost.thinking_ratio_a | pct -->75%<!-- /var --> of tasks but shallowly (<!-- var: cost.avg_thinking_when_used_a -->2,635<!-- /var --> avg chars). Over-thinks trivial tasks (&sect;3).</p>
                        <p><strong>Subagents:</strong> <!-- var: behavior.explore_count_a / behavior.total_subagents_a * 100 | .0f -->47<!-- /var -->% Explore, <!-- var: behavior.gp_count_a / behavior.total_subagents_a * 100 | .0f -->37<!-- /var -->% general-purpose (implementation workers). Primarily autonomous (<!-- var: behavior.subagent_autonomous_a / behavior.total_subagents_a * 100 | .0f -->54<!-- /var -->%).</p>
                        <p><strong>Planning:</strong> Rarely uses planning mode (<!-- var: planning.rate_a | .1f -->1.7<!-- /var -->%). Distributes research evenly through the task (&sect;4).</p>
                        <p><strong>Observed strengths:</strong> Lower tool overhead (mean <!-- var: stat.tool_calls_mean_a | .1f -->8.8<!-- /var --> calls/task). ~<!-- var: (cost.avg_cost_b / cost.avg_cost_a - 1) * 100 | .1f -->6.8<!-- /var -->% cheaper overall per task (&sect;2). Stable performance across session lengths (&sect;8).</p>
                        <p><strong>Observed weaknesses:</strong> Higher rewrite rate (<!-- var: edits.rewrite_rate_a | pct1 -->16.6%<!-- /var -->, &sect;6). Higher failure rate (<!-- var: stat.failed_rate_a * 100 | .1f -->13.2<!-- /var -->% vs <!-- var: stat.failed_rate_b * 100 | .1f -->8.6<!-- /var -->%, &sect;5).</p>
                    </div>
                    <div class="profile-card" style="border-left:3px solid var(--blue);">
                        <div class="label" style="color:var(--blue); font-family:'Poppins',sans-serif; font-size:0.65rem; font-weight:600; text-transform:uppercase; letter-spacing:0.08em;">Opus 4.6 &mdash; Observed Pattern</div>
                        <p><strong>Observed approach:</strong> Tends to research first, then implement. Front-loads investigation before touching files.</p>
                        <p><strong>Thinking:</strong> Thinks on <!-- var: cost.thinking_ratio_b | pct -->58%<!-- /var --> of tasks but deeply (<!-- var: cost.avg_thinking_when_used_b -->4,175<!-- /var --> avg chars). Better calibrated&mdash;skips thinking on trivial, engages on complex (&sect;3).</p>
                        <p><strong>Subagents:</strong> <!-- var: behavior.explore_count_b / behavior.total_subagents_b * 100 | .0f -->74<!-- /var -->% Explore (read-only research), <!-- var: behavior.gp_count_b / behavior.total_subagents_b * 100 | .0f -->15<!-- /var -->% general-purpose. More autonomous (<!-- var: behavior.subagent_autonomous_b / behavior.total_subagents_b * 100 | .0f -->84<!-- /var -->%).</p>
                        <p><strong>Planning:</strong> Uses planning mode on <!-- var: planning.rate_b | .1f -->13.9<!-- /var -->% of tasks (<!-- var: planning.total_planned_b -->82<!-- /var --> of <!-- var: planning.total_tasks_b -->591<!-- /var -->). <!-- var: planning.complex_rate_b | .0f -->51<!-- /var -->% at complex, <!-- var: planning.major_rate_b | .0f -->72<!-- /var -->% at major (&sect;4).</p>
                        <p><strong>Observed strengths:</strong> Lower rewrite rate (<!-- var: edits.rewrite_rate_b | pct1 -->10.3%<!-- /var -->, &sect;6). Lower failure rate (<!-- var: stat.failed_rate_b * 100 | .1f -->8.6<!-- /var -->%, &sect;5). Lower cost at trivial&ndash;moderate (&sect;2).</p>
                        <p><strong>Observed weaknesses:</strong> <!-- var: (dataset.total_tool_calls_b / dataset.tasks_b / (dataset.total_tool_calls_a / dataset.tasks_a) - 1) * 100 | .0f -->57<!-- /var -->% more tool calls per task (&sect;7). ~<!-- var: (cost.avg_cost_b / cost.avg_cost_a - 1) * 100 | .1f -->6.8<!-- /var -->% more expensive overall. Costlier at major complexity (n=<!-- var: cost.major_count_b | .0f -->18<!-- /var -->, &sect;2).</p>
                    </div>
                </div>

                <h3>Observed Patterns by Task Type</h3>
                <table>
                    <thead>
                        <tr><th>Task Type</th><th>Observed Pattern</th><th>Evidence &amp; Caveats</th></tr>
                    </thead>
                    <tbody>
                        <tr><td class="label-cell">Trivial / simple tasks</td><td>Similar completion rates</td><td>4.6 is 28&ndash;35% cheaper (&sect;2); n=<!-- var: dataset.complexity_trivial_a | .0f -->808<!-- /var -->/<!-- var: dataset.complexity_trivial_b | .0f -->213<!-- /var --> and <!-- var: dataset.complexity_simple_a | .0f -->345<!-- /var -->/<!-- var: dataset.complexity_simple_b | .0f -->129<!-- /var --></td></tr>
                        <tr><td class="label-cell">Complex / major tasks</td><td>4.6 showed higher alignment</td><td>n=<!-- var: dataset.complexity_complex_b | .0f -->74<!-- /var -->+<!-- var: dataset.complexity_major_b | .0f -->18<!-- /var --> for 4.6 vs <!-- var: dataset.complexity_complex_a | .0f -->190<!-- /var -->+<!-- var: dataset.complexity_major_a | .0f -->19<!-- /var --> for 4.5; confounded by project differences</td></tr>
                        <tr><td class="label-cell">Refactoring</td><td>4.6 produced <!-- var: tokens.refactor_output_b / tokens.refactor_output_a | x.1f -->4.3×<!-- /var --> output tokens</td><td><!-- var: tokens.refactor_output_b | ,.0f -->5,670<!-- /var --> vs <!-- var: tokens.refactor_output_a | ,.0f -->1,310<!-- /var --> avg output (&sect;2); lower rewrite rate (&sect;6)</td></tr>
                        <tr><td class="label-cell">Investigation / research</td><td>4.6 used more Explore agents</td><td><!-- var: behavior.explore_count_b / behavior.total_subagents_b * 100 | .0f -->74<!-- /var -->% read-only subagents (&sect;4); <!-- var: sessions.explore_median_b / sessions.explore_median_a | x.1f -->2.2×<!-- /var --> longer explore phase (&sect;8)</td></tr>
                        <tr><td class="label-cell">Long sessions (9+ tasks)</td><td>Both show some degradation</td><td>Small sample for late-session tasks; 4.6 may degrade faster</td></tr>
                        <tr><td class="label-cell">Parallel execution</td><td>4.6 backgrounded more tasks</td><td>4.5 spawned more agents but ran them sequentially</td></tr>
                    </tbody>
                </table>
            </section>

            <!-- ===== 10. METHODOLOGY ===== -->
            <section id="methodology"><h2>10. Methodology</h2>

                <!-- expand: data-cleaning -->

                <p>This section documents how each pipeline step works. Each step includes a summary of the approach and a collapsible detail block with thresholds, algorithms, and parameters.</p>

                <h3>Task Extraction &amp; Classification</h3>

                <p>Each Claude Code session was segmented into tasks at user-message boundaries. An LLM annotator (Haiku) then classified each task for complexity, type, sentiment, completion status, and alignment score (1&ndash;5 scale). Behavioral metrics&mdash;subagent usage, planning, parallelization&mdash;were extracted directly from tool-call logs.</p>

                <details><summary>Sentiment detection detail</summary>
                <p>Three independent signal sources feed into sentiment aggregation:</p>
                <ol>
                    <li><strong>Keyword patterns:</strong> Regex matching in user messages for positive signals (<em>thanks, perfect, excellent, looks good</em>), negative signals (<em>wrong, incorrect, please fix, revert, undo</em>), and continuation signals (<em>now, next, also, can you</em>). Confidence: low (0 hits), medium (1&ndash;2), high (&ge;3).</li>
                    <li><strong>Structural edit signals:</strong> Self-corrections (consecutive edits overlapping on same file), error recoveries (edits within 10 message indices of an error), user corrections (redirect patterns in the next user message), and rewrite rate (overlaps / total edits).</li>
                    <li><strong>LLM judgement:</strong> Haiku classifies the full task context. Free-text sentiment is normalized to satisfied/neutral/dissatisfied/ambiguous via pattern matching.</li>
                </ol>
                <p>Aggregation uses downgrade logic: if edit signals contradict the LLM (e.g., user corrections present but LLM says &ldquo;satisfied&rdquo;), the combined score is downgraded. If rewrite rate &gt;0.3 but execution quality is &ldquo;excellent,&rdquo; the quality score is downgraded to &ldquo;good.&rdquo;</p>
                </details>

                <h3>Cross-Cut Dimensions</h3>

                <p>All <!-- var: findings.total_tests -->529<!-- /var --> statistical tests are run both at the overall level and stratified across three cross-cut dimensions. Each section&rsquo;s &ldquo;Cross-Cut Detail&rdquo; expansion shows how its metrics behave under each slice.</p>

                <details><summary>Cross-cut dimension definitions</summary>
                <table>
                    <thead>
                        <tr><th>Dimension</th><th>Levels</th><th>Method</th></tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td class="label-cell">Complexity</td>
                            <td><strong>trivial</strong> (&le;3 tools, &le;1 file, &le;20 lines), <strong>simple</strong> (&le;10, &le;3, &le;100), <strong>moderate</strong> (&le;30, &le;10, &le;500), <strong>complex</strong> (&le;80, &le;25, &le;2000), <strong>major</strong> (above all thresholds)</td>
                            <td>Metric thresholds on tool calls, files touched, and lines changed. Lowest matching tier wins. Keyword heuristics as tiebreaker.</td>
                        </tr>
                        <tr>
                            <td class="label-cell">Task type</td>
                            <td><strong>investigation</strong>, <strong>bugfix</strong>, <strong>feature</strong>, <strong>greenfield</strong>, <strong>refactor</strong>, <strong>sysadmin</strong>, <strong>docs</strong>, <strong>continuation</strong>, <strong>port</strong></td>
                            <td>LLM-classified (Haiku) from user prompt, tool usage, and work summary. Regex pattern matching provides initial signal; LLM classification overrides at medium/high confidence, resolving previously &ldquo;unknown&rdquo; tasks (<!-- var: classify.unknown_rate * 100 | .1f -->34.3<!-- /var -->% of dataset). Eval: 100% unknown resolution, LLM agrees with regex on 55% of classified tasks.</td>
                        </tr>
                        <tr>
                            <td class="label-cell">Iteration</td>
                            <td><strong>one_shot</strong> (no back-and-forth), <strong>minor</strong> (small corrections), <strong>significant</strong> (multiple rework cycles)</td>
                            <td>LLM-classified from the user&rsquo;s next message after task completion, informed by edit signal heuristics (self-corrections, rewrite rate).</td>
                        </tr>
                    </tbody>
                </table>

                <div class="stat-note">
                    <strong>Minimum sample sizes:</strong> Cross-cut cells with fewer than 5&ndash;10 observations (depending on test type) are excluded from statistical testing. This primarily affects the &ldquo;major&rdquo; complexity tier (n=19/18) and rare task types.
                </div>
                </details>

                <h3>Edit Timeline Analysis</h3>

                <p>The edit timeline reconstructs a per-file content ownership history from every Edit/Write tool call across all sessions. When a later edit&rsquo;s <code>old_string</code> overlaps with content placed by an earlier edit, a rewrite is detected&mdash;providing a mechanistic signal for self-correction that doesn&rsquo;t depend on sentiment classification.</p>

                <details><summary>Overlap detection tiers and classification</summary>
                <p>Overlaps are matched via three tiers, evaluated in order:</p>
                <table>
                    <thead>
                        <tr><th>Tier</th><th>Method</th><th>Threshold</th></tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td class="label-cell">Exact</td>
                            <td>String equality between prior <code>new_string</code> and later <code>old_string</code></td>
                            <td>100% match</td>
                        </tr>
                        <tr>
                            <td class="label-cell">Containment</td>
                            <td>Substring match with size constraints</td>
                            <td>&ge;40 chars AND &ge;30% of larger string</td>
                        </tr>
                        <tr>
                            <td class="label-cell">Line overlap</td>
                            <td>Jaccard coefficient on non-trivial lines (&gt;15 chars)</td>
                            <td>Jaccard &gt;0.3 OR coverage &gt;0.5</td>
                        </tr>
                    </tbody>
                </table>

                <p>Each detected overlap is classified by context:</p>
                <ul>
                    <li><strong>Self-correction:</strong> Same task, no intervening user prompt or errors</li>
                    <li><strong>Error recovery:</strong> Error detected between the two edits</li>
                    <li><strong>User-directed:</strong> Dissatisfaction keyword in intervening user message</li>
                    <li><strong>Iterative refinement:</strong> Chain depth &gt;3, or none of the above</li>
                </ul>

                <p>A per-task <em>triage score</em> weights these: <code>(self_corrections&times;3 + error_recoveries&times;2 + user_corrections&times;5 + max_chain_depth) / total_edits</code>. Edit metrics were joined with task classifications to compute complexity-binned accuracy rates (100% coverage for both models).</p>
                </details>

                <h3>Compaction Analysis</h3>

                <p>Claude Code compacts conversation context when token limits approach. This analysis measures whether compaction degrades task outcomes or merely correlates with session position.</p>

                <details><summary>Compaction detection and outcome measurement</summary>
                <p><!-- var: compaction.total_events_a + compaction.total_events_b | .0f -->79<!-- /var --> <code>compact_boundary</code> system messages were found across <!-- var: compaction.sessions_a + compaction.sessions_b | .0f -->50<!-- /var --> compacting sessions, with trigger type, pre-compaction token count, and session position extracted for each. Outcome impact was measured by splitting tasks into pre/post groups at the first compaction timestamp. A control group of non-compacting sessions, split at the median compaction position, isolates position effects from compaction effects.</p>
                </details>

                <h3>Statistical Testing</h3>

                <p><!-- var: findings.total_tests -->529<!-- /var --> tests were conducted across overall and per-complexity strata, using Bonferroni correction&mdash;the most conservative standard&mdash;to minimize false positives given the observational design.</p>

                <details><summary>Test types, effect sizes, and correction thresholds</summary>
                <p>Three test types were used: chi-square for categorical distributions (effect size: Cram&eacute;r&rsquo;s V), Mann-Whitney U for continuous metrics (Cohen&rsquo;s d with bootstrap confidence intervals, n=5,000 resamples), and two-proportion Z-tests for rates (Cohen&rsquo;s h). Confidence intervals on proportions use Wilson score intervals.</p>

                <p>Bonferroni corrected threshold: p&lt;<!-- var: 0.05 / findings.total_tests | .7f -->0.0000945<!-- /var -->. Across all <!-- var: findings.total_tests -->529<!-- /var --> tests, <!-- var: findings.bonferroni_significant -->93<!-- /var --> survive Bonferroni and <!-- var: findings.fdr_significant -->168<!-- /var --> survive FDR correction. At the overall level, <!-- var: stats.overall_bonferroni_count | .0f -->15<!-- /var --> survive Bonferroni, including alignment score (p=<!-- var: quality.alignment_p -->0.000023<!-- /var -->), duration (p&lt;0.000001, though d=<!-- var: stat.duration_d -->0.005<!-- /var -->&mdash;negligible practical effect), tool calls/task (p&lt;0.000001, d=&minus;<!-- var: -1 * stat.tool_calls_d | .2f -->0.29<!-- /var -->), tools/file (p&lt;0.000001, d=&minus;<!-- var: -1 * stat.tools_per_file_d | .2f -->0.10<!-- /var -->), and three categorical distributions (task completion, communication quality, autonomy level). Two of the three chi-square survivors have low-expected-cell-count warnings, which may inflate their test statistics.</p>
                </details>

                <!-- expand: stat-test-full-results -->

                <h3>Sensitivity Analysis</h3>

                <p>To validate robustness, all overall-level tests were re-run on a restricted dataset excluding overlapping projects. This tests whether findings depend on specific project mix or are stable across the data.</p>

                <!-- expand: sensitivity-analysis -->

                <h3>Ranked Findings</h3>

<!-- GENERATED-TABLE: findings-summary -->
<table>
    <thead>
        <tr><th>#</th><th>Measurement</th><th>Theme</th><th>Direction</th><th class="right">Effect</th><th class="right">p<sub>adj</sub></th><th>Sig</th></tr>
    </thead>
    <tbody>
        <tr>
            <td class="right mono">1</td>
            <td class="label-cell">Thinking Fraction</td>
            <td>Thinking</td>
            <td>opus-4-5 higher</td>
            <td class="right mono">0.674 medium <div class="bar-single"><div class="bar-track" style="width:60px"><div class="bar-fill green" style="width:100%"></div></div></div></td>
            <td class="right mono">0.0000</td>
            <td><span class="v-green">Bonf</span></td>
        </tr>
        <tr>
            <td class="right mono">2</td>
            <td class="label-cell">Total Output Tokens</td>
            <td>Cost</td>
            <td>opus-4-6 higher</td>
            <td class="right mono">0.424 small <div class="bar-single"><div class="bar-track" style="width:60px"><div class="bar-fill green" style="width:85%"></div></div></div></td>
            <td class="right mono">0.0000</td>
            <td><span class="v-green">Bonf</span></td>
        </tr>
        <tr>
            <td class="right mono">3</td>
            <td class="label-cell">Output Per Request</td>
            <td>Cost</td>
            <td>opus-4-6 higher</td>
            <td class="right mono">0.329 small <div class="bar-single"><div class="bar-track" style="width:60px"><div class="bar-fill green" style="width:66%"></div></div></div></td>
            <td class="right mono">0.0000</td>
            <td><span class="v-green">Bonf</span></td>
        </tr>
        <tr>
            <td class="right mono">4</td>
            <td class="label-cell">Tool Calls</td>
            <td>Behavior</td>
            <td>opus-4-6 higher</td>
            <td class="right mono">0.286 small <div class="bar-single"><div class="bar-track" style="width:60px"><div class="bar-fill green" style="width:57%"></div></div></div></td>
            <td class="right mono">0.0000</td>
            <td><span class="v-green">Bonf</span></td>
        </tr>
        <tr>
            <td class="right mono">5</td>
            <td class="label-cell">Request Count</td>
            <td>Cost</td>
            <td>opus-4-6 higher</td>
            <td class="right mono">0.241 small <div class="bar-single"><div class="bar-track" style="width:60px"><div class="bar-fill green" style="width:48%"></div></div></div></td>
            <td class="right mono">0.0000</td>
            <td><span class="v-green">Bonf</span></td>
        </tr>
        <tr>
            <td class="right mono">6</td>
            <td class="label-cell">Files Touched</td>
            <td>Behavior</td>
            <td>equal</td>
            <td class="right mono">0.233 small <div class="bar-single"><div class="bar-track" style="width:60px"><div class="bar-fill green" style="width:47%"></div></div></div></td>
            <td class="right mono">0.0213</td>
            <td><span class="v-blue">FDR</span></td>
        </tr>
        <tr>
            <td class="right mono">7</td>
            <td class="label-cell">Alignment Score</td>
            <td>Quality</td>
            <td>equal</td>
            <td class="right mono">0.206 small <div class="bar-single"><div class="bar-track" style="width:60px"><div class="bar-fill green" style="width:41%"></div></div></div></td>
            <td class="right mono">0.0001</td>
            <td><span class="v-green">Bonf</span></td>
        </tr>
        <tr>
            <td class="right mono">8</td>
            <td class="label-cell">Cost Per Minute</td>
            <td>Cost</td>
            <td>opus-4-5 higher</td>
            <td class="right mono">0.192 negligible <div class="bar-single"><div class="bar-track" style="width:60px"><div class="bar-fill green" style="width:38%"></div></div></div></td>
            <td class="right mono">0.0000</td>
            <td><span class="v-green">Bonf</span></td>
        </tr>
        <tr>
            <td class="right mono">9</td>
            <td class="label-cell">Communication Quality</td>
            <td>Behavior</td>
            <td>distributions differ</td>
            <td class="right mono">0.157 negligible <div class="bar-single"><div class="bar-track" style="width:60px"><div class="bar-fill green" style="width:31%"></div></div></div></td>
            <td class="right mono">0.0000</td>
            <td><span class="v-green">Bonf</span></td>
        </tr>
        <tr>
            <td class="right mono">10</td>
            <td class="label-cell">Cache Hit Rate</td>
            <td>Cost</td>
            <td>equal</td>
            <td class="right mono">0.154 negligible <div class="bar-single"><div class="bar-track" style="width:60px"><div class="bar-fill green" style="width:31%"></div></div></div></td>
            <td class="right mono">0.0000</td>
            <td><span class="v-green">Bonf</span></td>
        </tr>
        <tr>
            <td class="right mono">11</td>
            <td class="label-cell">Autonomy Level</td>
            <td>Behavior</td>
            <td>distributions differ</td>
            <td class="right mono">0.151 negligible <div class="bar-single"><div class="bar-track" style="width:60px"><div class="bar-fill green" style="width:30%"></div></div></div></td>
            <td class="right mono">0.0000</td>
            <td><span class="v-green">Bonf</span></td>
        </tr>
        <tr>
            <td class="right mono">12</td>
            <td class="label-cell">Failed Rate</td>
            <td>Quality</td>
            <td>opus-4-5 higher</td>
            <td class="right mono">0.149 negligible <div class="bar-single"><div class="bar-track" style="width:60px"><div class="bar-fill green" style="width:30%"></div></div></div></td>
            <td class="right mono">0.0120</td>
            <td><span class="v-blue">FDR</span></td>
        </tr>
        <tr>
            <td class="right mono">13</td>
            <td class="label-cell">Scope Management</td>
            <td>Behavior</td>
            <td>distributions differ</td>
            <td class="right mono">0.140 negligible <div class="bar-single"><div class="bar-track" style="width:60px"><div class="bar-fill green" style="width:28%"></div></div></div></td>
            <td class="right mono">0.0017</td>
            <td><span class="v-blue">FDR</span></td>
        </tr>
        <tr>
            <td class="right mono">14</td>
            <td class="label-cell">Scope Expanded Rate</td>
            <td>Behavior</td>
            <td>opus-4-5 higher</td>
            <td class="right mono">0.139 negligible <div class="bar-single"><div class="bar-track" style="width:60px"><div class="bar-fill green" style="width:28%"></div></div></div></td>
            <td class="right mono">0.0457</td>
            <td><span class="v-blue">FDR</span></td>
        </tr>
        <tr>
            <td class="right mono">15</td>
            <td class="label-cell">Error Recovery</td>
            <td></td>
            <td>distributions differ</td>
            <td class="right mono">0.135 negligible <div class="bar-single"><div class="bar-track" style="width:60px"><div class="bar-fill green" style="width:27%"></div></div></div></td>
            <td class="right mono">0.0284</td>
            <td><span class="v-blue">FDR</span></td>
        </tr>
        <tr>
            <td class="right mono">16</td>
            <td class="label-cell">Iteration Required</td>
            <td>Behavior</td>
            <td>distributions differ</td>
            <td class="right mono">0.126 negligible <div class="bar-single"><div class="bar-track" style="width:60px"><div class="bar-fill green" style="width:25%"></div></div></div></td>
            <td class="right mono">0.0035</td>
            <td><span class="v-blue">FDR</span></td>
        </tr>
        <tr>
            <td class="right mono">17</td>
            <td class="label-cell">Satisfaction Rate</td>
            <td>Quality</td>
            <td>opus-4-6 higher</td>
            <td class="right mono">0.118 negligible <div class="bar-single"><div class="bar-track" style="width:60px"><div class="bar-fill green" style="width:24%"></div></div></div></td>
            <td class="right mono">0.0390</td>
            <td><span class="v-blue">FDR</span></td>
        </tr>
        <tr>
            <td class="right mono">18</td>
            <td class="label-cell">Thinking Chars</td>
            <td>Thinking</td>
            <td>opus-4-5 higher</td>
            <td class="right mono">0.115 negligible <div class="bar-single"><div class="bar-track" style="width:60px"><div class="bar-fill green" style="width:23%"></div></div></div></td>
            <td class="right mono">0.0000</td>
            <td><span class="v-green">Bonf</span></td>
        </tr>
        <tr>
            <td class="right mono">19</td>
            <td class="label-cell">Total Input Tokens</td>
            <td>Cost</td>
            <td>opus-4-5 higher</td>
            <td class="right mono">0.112 negligible <div class="bar-single"><div class="bar-track" style="width:60px"><div class="bar-fill green" style="width:22%"></div></div></div></td>
            <td class="right mono">0.0000</td>
            <td><span class="v-green">Bonf</span></td>
        </tr>
        <tr>
            <td class="right mono">20</td>
            <td class="label-cell">Task Completion</td>
            <td>Quality</td>
            <td>distributions differ</td>
            <td class="right mono">0.103 negligible <div class="bar-single"><div class="bar-track" style="width:60px"><div class="bar-fill green" style="width:21%"></div></div></div></td>
            <td class="right mono">0.0001</td>
            <td><span class="v-green">Bonf</span></td>
        </tr>
        <tr>
            <td class="right mono">21</td>
            <td class="label-cell">Tools Per File</td>
            <td>Behavior</td>
            <td>opus-4-6 higher</td>
            <td class="right mono">0.096 negligible <div class="bar-single"><div class="bar-track" style="width:60px"><div class="bar-fill green" style="width:19%"></div></div></div></td>
            <td class="right mono">0.0000</td>
            <td><span class="v-green">Bonf</span></td>
        </tr>
        <tr>
            <td class="right mono">22</td>
            <td class="label-cell">Duration Seconds</td>
            <td>Behavior</td>
            <td>opus-4-6 higher</td>
            <td class="right mono">0.005 negligible <div class="bar-single"><div class="bar-track" style="width:60px"><div class="bar-fill green" style="width:1%"></div></div></div></td>
            <td class="right mono">0.0000</td>
            <td><span class="v-green">Bonf</span></td>
        </tr>
    </tbody>
</table>
<details><summary>16 non-significant overall results</summary>
<table>
    <thead>
        <tr><th>Measurement</th><th>Theme</th><th class="right">Effect</th><th class="right">p<sub>adj</sub></th></tr>
    </thead>
    <tbody>
        <tr><td>Triage Score</td><td>Editing</td><td class="right mono">0.133</td><td class="right mono">0.1371</td></tr>
        <tr><td>Rewrite Rate</td><td>Editing</td><td class="right mono">0.131</td><td class="right mono">0.1270</td></tr>
        <tr><td>Max Chain Depth</td><td>Editing</td><td class="right mono">0.121</td><td class="right mono">0.1448</td></tr>
        <tr><td>Lines Removed</td><td>Editing</td><td class="right mono">0.119</td><td class="right mono">0.7336</td></tr>
        <tr><td>Complete Rate</td><td>Quality</td><td class="right mono">0.106</td><td class="right mono">0.0756</td></tr>
        <tr><td>Lines Per Minute</td><td>Behavior</td><td class="right mono">0.095</td><td class="right mono">0.8466</td></tr>
        <tr><td>Has Overlaps Rate</td><td>Editing</td><td class="right mono">0.087</td><td class="right mono">0.1762</td></tr>
        <tr><td>Estimated Cost</td><td>Cost</td><td class="right mono">0.082</td><td class="right mono">0.4459</td></tr>
        <tr><td>Normalized Execution Quality</td><td>Quality</td><td class="right mono">0.053</td><td class="right mono">0.3141</td></tr>
        <tr><td>Normalized User Sentiment</td><td>Quality</td><td class="right mono">0.052</td><td class="right mono">0.2109</td></tr>
        <tr><td>Has Edits Rate</td><td>Editing</td><td class="right mono">0.048</td><td class="right mono">0.4710</td></tr>
        <tr><td>Overlap Count</td><td>Editing</td><td class="right mono">0.037</td><td class="right mono">0.1784</td></tr>
        <tr><td>Good Execution Rate</td><td>Quality</td><td class="right mono">0.022</td><td class="right mono">0.7336</td></tr>
        <tr><td>Dissatisfaction Rate</td><td>Quality</td><td class="right mono">0.022</td><td class="right mono">0.7472</td></tr>
        <tr><td>One Shot Rate</td><td>Behavior</td><td class="right mono">0.019</td><td class="right mono">0.7782</td></tr>
        <tr><td>Lines Added</td><td>Editing</td><td class="right mono">0.015</td><td class="right mono">0.3658</td></tr>
    </tbody>
</table>
</details>
<!-- /GENERATED-TABLE: findings-summary -->

                <h3>Development Process</h3>

                <p>This analysis was developed iteratively. Two early approaches were replaced after proving unreliable:</p>

                <details><summary>Abandoned approaches</summary>
                <p><strong>LLM-only dissatisfaction detection:</strong> Initial LLM-based sentiment classification flagged 7&ndash;9% dissatisfaction for both models. An audit of all 59 flagged cases revealed 73&ndash;93% false positive rates&mdash;the classifiers were fooled by task-coordination language (e.g., &ldquo;fix&rdquo; in subagent prompts). This was replaced by the current multi-signal approach, which requires corroboration from keyword patterns and structural edit signals before classifying dissatisfaction.</p>

                <p><strong>LLM quality judgement:</strong> An LLM judge was asked to compare code quality between models. The judge lacked sufficient context to evaluate whether code met domain requirements and produced confident but ungrounded assessments. This was replaced by mechanistic edit timeline analysis, which detects self-corrections from the tool-call record rather than relying on subjective quality assessment.</p>
                </details>

                <h3>Reproducing This Analysis</h3>
                <!-- expand: reproduction -->

                <h3>Limitations</h3>
                <p><strong>LLM-in-the-loop analysis:</strong> All task classification, sentiment analysis, and alignment scoring was performed by LLM agents (Claude Haiku and Sonnet). This creates a circularity concern: Claude models are classifying Claude model outputs. No formal inter-rater reliability was computed. Human spot-checks validated flagged cases, but systematic bias between models (e.g., if the classifier is more generous toward outputs that resemble its own style) cannot be ruled out. All three overall chi-square Bonferroni survivors and the alignment score depend on LLM-generated categories.</p>
                <p><strong>Single user:</strong> All data comes from one developer&rsquo;s workflow. Results may not generalize to other users, codebases, or task distributions.</p>
                <p><strong>Temporal confound:</strong> Opus 4.5 spans 2 months; Opus 4.6 spans 9 days. A productive week, a particular project focus, or simply the novelty of a new model could color all <!-- var: dataset.tasks_b | .0f -->591<!-- /var --> Opus 4.6 tasks simultaneously. The null hypothesis&mdash;that all observed differences reflect the user&rsquo;s changing work patterns rather than model capabilities&mdash;cannot be rejected by this design.</p>
                <p><strong>Observational, not experimental:</strong> Tasks were not randomly assigned to models. Opus 4.6 was used later chronologically and on different (often harder) tasks, confounding model effects with task effects.</p>
                <p><strong>Complexity confound:</strong> Opus 4.6&rsquo;s different complexity mix (<!-- var: (dataset.complexity_moderate_b + dataset.complexity_complex_b + dataset.complexity_major_b) / dataset.tasks_b * 100 | .0f -->42<!-- /var -->% moderate-and-above vs <!-- var: (dataset.complexity_moderate_a + dataset.complexity_complex_a + dataset.complexity_major_a) / dataset.tasks_a * 100 | .0f -->33<!-- /var -->% for Opus 4.5) inflates its resource usage metrics and may suppress its satisfaction scores. Complexity-stratified comparisons (presented throughout as cross-cut detail) partially control for this, but cannot fully separate model effects from mix effects.</p>
                <p><strong>Platform evolution:</strong> The Claude Code SDK evolved between December 2025 and February 2026. Changes to system prompts, available tools, or subagent defaults could contribute to behavioral differences attributed to the models.</p>
                <p><strong>Sample asymmetry:</strong> The <!-- var: dataset.tasks_a / dataset.tasks_b | .1f -->2.9<!-- /var -->:1 ratio (<!-- var: dataset.tasks_a -->1,729<!-- /var --> vs <!-- var: dataset.tasks_b -->591<!-- /var --> tasks) means Opus 4.5 estimates have narrower confidence intervals. Effect sizes for Opus 4.6 are less precise.</p>
                <p><strong>User learning effect:</strong> The user may have learned to use Claude Code more effectively over time, benefiting whichever model came second in the chronological sequence.</p>
</section>

            <section id="acknowledgments" style="margin-top:2rem; padding-top:1rem; border-top:1px solid var(--light-gray);">
                <p style="font-size:0.85rem; color:var(--gray);">Thanks to Anthropic for including me in the Claude Code Early Access Program and for supporting independent research into model behavior. The EAP provided early access to Opus 4.6, making this comparative analysis possible.</p>
            </section>

            <footer>
                Claude Code Early Access Program &middot; Single-user exploratory case study &middot; February 2026
            </footer>

        </div>
    </body>
</html>