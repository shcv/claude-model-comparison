<!-- title: Token volumes and code output -->
<!-- GENERATED-TABLE -->
<p>Raw token volumes across the full dataset. These are absolute totals, not per-task averages (see <a href="#cost">&sect;2</a> for normalized comparisons).</p>

<table>
    <thead>
        <tr>
            <th>Metric</th>
            <th class="right">Opus 4.5</th>
            <th class="right">Opus 4.6</th>
            <th class="right">Combined</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td class="label-cell">Output tokens</td>
            <td class="right mono">2.1M</td>
            <td class="right mono">1.8M</td>
            <td class="right mono">3.8M</td>
        </tr>
        <tr>
            <td class="label-cell">Input tokens (fresh)</td>
            <td class="right mono">676,988</td>
            <td class="right mono">114,113</td>
            <td class="right mono">791,101</td>
        </tr>
        <tr>
            <td class="label-cell">Cache read tokens</td>
            <td class="right mono">1.28B</td>
            <td class="right mono">632.9M</td>
            <td class="right mono">1.91B</td>
        </tr>
        <tr>
            <td class="label-cell">Cache write tokens</td>
            <td class="right mono">145.6M</td>
            <td class="right mono">40.2M</td>
            <td class="right mono">185.8M</td>
        </tr>
        <tr>
            <td class="label-cell">Total API cost</td>
            <td class="right mono">$5,292.01</td>
            <td class="right mono">$2,074.07</td>
            <td class="right mono">$7,366.08</td>
        </tr>
    </tbody>
</table>

<h3>Output composition</h3>
<p>Model output splits into <em>thinking</em> (extended thinking / chain-of-thought, not billed as output) and <em>text</em> (visible response, code, tool calls). Estimated from character counts with a 3:1 chars-to-tokens ratio for thinking.</p>

<table>
    <thead>
        <tr>
            <th>Metric</th>
            <th class="right">Opus 4.5</th>
            <th class="right">Opus 4.6</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td class="label-cell">Est. thinking tokens</td>
            <td class="right mono">1,419,559</td>
            <td class="right mono">637,794</td>
        </tr>
        <tr>
            <td class="label-cell">Est. text tokens</td>
            <td class="right mono">674,821</td>
            <td class="right mono">342,595</td>
        </tr>
        <tr>
            <td class="label-cell">Thinking ratio (tasks using thinking)</td>
            <td class="right mono">75.1%</td>
            <td class="right mono">58.7%</td>
        </tr>
        <tr>
            <td class="label-cell">Avg requests / task</td>
            <td class="right mono">7.5</td>
            <td class="right mono">9.7</td>
        </tr>
    </tbody>
</table>

<h3>Code output</h3>
<table>
    <thead>
        <tr>
            <th>Metric</th>
            <th class="right">Opus 4.5</th>
            <th class="right">Opus 4.6</th>
            <th class="right">Combined</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td class="label-cell">Files touched</td>
            <td class="right mono">2,893</td>
            <td class="right mono">1,520</td>
            <td class="right mono">4,413</td>
        </tr>
        <tr>
            <td class="label-cell">Lines added</td>
            <td class="right mono">178,794</td>
            <td class="right mono">63,898</td>
            <td class="right mono">242,692</td>
        </tr>
        <tr>
            <td class="label-cell">Lines removed</td>
            <td class="right mono">37,493</td>
            <td class="right mono">16,877</td>
            <td class="right mono">54,370</td>
        </tr>
    </tbody>
</table>

<p>Cache reads dominate the token budget: 91% of all tokens processed were served from cache rather than freshly encoded. This reflects Claude Code's prompt architecture, where the system prompt and conversation history are re-sent with each API call but largely hit the prompt cache.</p>
<!-- /GENERATED-TABLE -->
