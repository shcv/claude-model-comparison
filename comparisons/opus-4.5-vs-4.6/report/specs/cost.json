{
  "section_id": "cost",
  "review": {
    "intent": "Compare token economics between models, showing how output volume, thinking depth, and caching interact to determine per-task cost.",
    "focus": [
      "Verify cost-per-task figures match token-analysis.json calculations",
      "Check that complexity-stratified cost claims don't contradict the overall cost comparison",
      "Ensure caching efficiency narrative is consistent with cache_hit_rate data",
      "Confirm verbosity-by-type table rows use the correct task type taxonomy (no stale 'simple' type)"
    ]
  },
  "data_sources": {
    "tokens": "analysis/token-analysis.json"
  },
  "tables": {
    "cost-by-complexity": {
      "title": "Token breakdown by complexity level",
      "data_source": "tokens",
      "row_source": "by_complexity",
      "row_order": [
        "trivial",
        "simple",
        "moderate",
        "complex",
        "major"
      ],
      "columns": [
        {
          "header": "Complexity",
          "key": "_label",
          "cell_class": "label-cell"
        },
        {
          "header": "{display_a} output/task",
          "path": "tokens.{model_a}.by_complexity.{row_key}.avg_output_tokens",
          "format": "{:,.0f}",
          "class": "right",
          "cell_class": "right mono"
        },
        {
          "header": "{display_b} output/task",
          "path": "tokens.{model_b}.by_complexity.{row_key}.avg_output_tokens",
          "format": "{:,.0f}",
          "class": "right",
          "cell_class": "right mono"
        },
        {
          "header": "{display_a} thinking chars",
          "path": "tokens.{model_a}.by_complexity.{row_key}.avg_thinking_chars_when_used",
          "format": "{:,.0f}",
          "class": "right",
          "cell_class": "right mono"
        },
        {
          "header": "{display_b} thinking chars",
          "path": "tokens.{model_b}.by_complexity.{row_key}.avg_thinking_chars_when_used",
          "format": "{:,.0f}",
          "class": "right",
          "cell_class": "right mono"
        },
        {
          "header": "{display_a} input/task",
          "path": "tokens.{model_a}.by_complexity.{row_key}.avg_input_tokens",
          "format": "{:,.0f}",
          "class": "right",
          "cell_class": "right mono"
        },
        {
          "header": "{display_b} input/task",
          "path": "tokens.{model_b}.by_complexity.{row_key}.avg_input_tokens",
          "format": "{:,.0f}",
          "class": "right",
          "cell_class": "right mono"
        },
        {
          "header": "{display_a} requests",
          "path": "tokens.{model_a}.by_complexity.{row_key}.avg_requests_per_task",
          "format": "{:.1f}",
          "class": "right",
          "cell_class": "right mono"
        },
        {
          "header": "{display_b} requests",
          "path": "tokens.{model_b}.by_complexity.{row_key}.avg_requests_per_task",
          "format": "{:.1f}",
          "class": "right",
          "cell_class": "right mono"
        }
      ],
      "prose": {
        "guidance": "Explain token breakdown patterns: output volume differences, thinking depth, input savings from caching, request batching efficiency."
      }
    },
    "thinking-calibration-details": {
      "title": "Thinking depth by complexity",
      "data_source": "tokens",
      "row_source": "by_complexity",
      "row_order": [
        "trivial",
        "simple",
        "moderate",
        "complex",
        "major"
      ],
      "columns": [
        {
          "header": "Complexity",
          "key": "_label",
          "cell_class": "label-cell"
        },
        {
          "header": "{display_a} Thinking Chars (when used)",
          "path": "tokens.{model_a}.by_complexity.{row_key}.avg_thinking_chars_when_used",
          "format": "{:,.0f}",
          "class": "right",
          "cell_class": "right mono"
        },
        {
          "header": "{display_b} Thinking Chars (when used)",
          "path": "tokens.{model_b}.by_complexity.{row_key}.avg_thinking_chars_when_used",
          "format": "{:,.0f}",
          "class": "right",
          "cell_class": "right mono"
        },
        {
          "header": "{display_a} Text Chars",
          "path": "tokens.{model_a}.by_complexity.{row_key}.avg_text_chars",
          "format": "{:,.0f}",
          "class": "right",
          "cell_class": "right mono"
        },
        {
          "header": "{display_b} Text Chars",
          "path": "tokens.{model_b}.by_complexity.{row_key}.avg_text_chars",
          "format": "{:,.0f}",
          "class": "right",
          "cell_class": "right mono"
        },
        {
          "header": "{display_a} Think/Text",
          "numerator": "tokens.{model_a}.by_complexity.{row_key}.avg_thinking_chars_when_used",
          "denominator": "tokens.{model_a}.by_complexity.{row_key}.avg_text_chars",
          "format": "{:.2f}",
          "class": "right",
          "cell_class": "right mono"
        },
        {
          "header": "{display_b} Think/Text",
          "numerator": "tokens.{model_b}.by_complexity.{row_key}.avg_thinking_chars_when_used",
          "denominator": "tokens.{model_b}.by_complexity.{row_key}.avg_text_chars",
          "format": "{:.2f}",
          "class": "right",
          "cell_class": "right mono"
        }
      ],
      "prose": {
        "guidance": "Explain thinking calibration differences between models: how thinking depth varies across complexity levels for each model. Characterize any gradient differences in thinking allocation."
      }
    },
    "per-request-output": {
      "title": "Per-request output by complexity",
      "data_source": "tokens",
      "row_gen": "per_request_output"
    },
    "cost-verbosity-by-type": {
      "title": "Output verbosity by task type",
      "data_source": "tokens",
      "row_gen": "verbosity_by_type"
    },
    "cost-by-complexity-inline": {
      "title": "Cost by complexity",
      "data_source": "tokens",
      "row_gen": "cost_by_complexity"
    },
    "cost-cache-efficiency": {
      "title": "Cache Efficiency by Complexity",
      "data_source": "tokens",
      "row_gen": "cache_efficiency"
    }
  },
  "prose": {
    "key_metrics": [
      "tokens.{model_a}.overall.avg_cost_usd",
      "tokens.{model_b}.overall.avg_cost_usd",
      "tokens.{model_a}.overall.avg_output_tokens",
      "tokens.{model_b}.overall.avg_output_tokens",
      "tokens.{model_a}.overall.avg_input_tokens",
      "tokens.{model_b}.overall.avg_input_tokens",
      "tokens.{model_a}.overall.thinking_ratio",
      "tokens.{model_b}.overall.thinking_ratio",
      "tokens.{model_a}.overall.avg_requests_per_task",
      "tokens.{model_b}.overall.avg_requests_per_task",
      "tokens.{model_a}.overall.count",
      "tokens.{model_b}.overall.count"
    ],
    "guidance": "This section covers token economy. Explain the relationship between output volume, caching efficiency, and per-task cost. Verify all cost, token count, and ratio claims against the data. Complexity-stratified claims should be consistent with overall figures."
  }
}
